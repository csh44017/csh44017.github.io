[
  
  {
    "title": "Pythonic Code",
    "url": "/posts/pythonic_code/",
    "categories": "Python",
    "tags": "Python",
    "date": "2023-05-13 00:00:00 +0900",
    





    "snippet": "Pythonic 코드파이썬스러운 코드로, Python 언어의 규칙을 준수하면서 가독성이 좋고 클린한 코드를 작성하여 파이썬 생태계와 잘 통합될 수 있도록 한다.Pythonic code를 작성하기 위해 참고할 만한 것들과 헷갈릴 수 있는 부분을 정리해보았다.데이터 타입동적 타이핑 언어인 파이썬에서는 변수의 데이터 타입이 실행 중에 자동으로 결정되기 때문에 변수를 선언할 때 데이터 타입을 지정해주지 않아도 된다.  숫자 (Number)          int      float      complex        문자열 (String)          str        불리언 (Boolean)          bool        시퀀스 (Sequence)          list      tuple      str      range        매핑 (Mapping)          dict        집합 (Set)          set      frozenset        바이트 시퀀스 (Byte Sequence)          bytes      bytearray        None          NoneType      데이터 구조      시퀀스 (Sequence)순서가 있는 데이터 구조각 요소가 인덱스에 따라 정렬되므로 인덱스를 통해 개별 요소에 접근할 수 있으며 슬라이싱 기능을 사용할 수 있다.    ex) 리스트(List), 튜플(Tuple), 문자열(String), 범위(range), 바이트(bytes), 바이트어레이(bytearray)    # listnumbers = [1, 2, 3, 4, 5]print(numbers[2])print(numbers[1:3])# tupleage = (11, 19, 37)print(age[1])# stringtext = 'bear'print(text[0])        3[2, 3]19'b'            컨테이너 (Container)여러 요소나 객체를 저장하는 데이터 구조순서에 상관없이 요소를 보관하므로 인덱스로 접근이 불가능하지만, 반복 작업이나 검색, 추가, 삭제와 같은 기능을 수행할 수 있다.    ex) 리스트(List), 세트(Set), 딕셔너리(Dictionary), 큐(Queue)(리스트는 시퀀스와 컨테이너 모두에 해당)    # listnumbers = [1, 2, 3, 4, 5]print(numbers*2)# setmy_set = {1, 2, 3, 3, 4}print(\"중복 요소 제거 :\", my_set)set1 = {1, 2, 3}set2 = {3, 4, 5}print('합집합 :', set1 | set2)  # Unionprint('교집합 :', set1 &amp; set2)  # Intersectionprint('차집합 :', set1 - set2)  # Difference# dictionaryanimals = ['bear', 'dog', 'cat', 'bear', 'bear']key = list(set(animals))  # ['bear', 'dog', 'cat']animal_dict = {'bear': 1, 'dog': 2, 'cat':3}classes = [animal_dict[k] for k in key]print(classes)# queueimport queuemy_queue = queue.Queue()my_queue.put(5)my_queue.put(7)my_queue.put(9)while not my_queue.empty():    item = my_queue.get()    print(item)        [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]중복 요소 제거 : {1, 2, 3, 4}합집합 : {1, 2, 3, 4, 5}교집합 : {3}차집합 : {1, 2}[1, 2, 3]579          ‘list’와 ‘numpy.ndarray’ 간에 주의힐 점  +연산          list : 리스트 추가 or 요소와 숫자의 덧셈      ndarray : 전체 요소에 각각 덧셈 연산 or 각 차원끼리 덧셈```pythonimport numpy as np        list    my_list = [[1, 2, 3], [4, 5, 6]]print(my_list + [[1, 2]])  # 연산할 리스트의 크기는 고려하지 않음    numpy.ndarray    matrix = np.array([[1, 2, 3], [4, 5, 6]])print(matrix + 1)print(matrix + matrix)  # 연산할 행렬의 크기가 동일해야 함    ```shell[[1, 2, 3], [4, 5, 6], [1, 2]]array([[2, 3, 4],       [5, 6, 7]])array([[ 2,  4,  6],       [ 8, 10, 12]])        *연산          list : 리스트 자체를 반복      ndarray : 전체 요소에 각각 곱셈 연산```pythonimport numpy as np        list    my_list = [[1, 2, 3], [4, 5, 6]]print(my_list * 2)    numpy.ndarray    matrix = np.array([[1, 2, 3], [4, 5, 6]])print(matrix * 2))print(matrix * matrix))  # 연산할 행렬의 크기가 동일해야 함    ```shell[[1, 2, 3], [4, 5, 6], [1, 2, 3], [4, 5, 6]]array([[ 2,  4,  6],       [ 8, 10, 12]])array([[ 1,  4,  9],       [16, 25, 36]])          데이터의 크기 조회  .shape1차원 구조이거나 key-value 쌍으로 구성되는 데이터는 shape의 개념이 없음–&gt; (행, 열) tuple 반환  .size전체 요소의 개수가 데이터의 길이와 같은 경우는 len으로 확인–&gt; ‘행x열’의 전체 요소 개수 int 반환      len()데이터의 길이 확인 가능–&gt; 데이터의 길이 int 반환    |      |Tuple|List|ndarray|Set|Dictionary|Dataframe||——|—–|—-|——-|—|———-|———||.shape|X    |X   |O      |X  |X         |O        ||.size |X    |X   |O      |X  |X         |O        ||len() |O    |O   |O      |O  |O         |O        |  데이터 처리  map()주어진 함수를 iterable 객체의 모든 요소에 적용          사용법        \"\"\" map(각 요소에 적용할 함수, 함수를 적용할 반복가능한 객체) \"\"\"map(function, iterable)                    결과        &lt;map object at 0x000001BF8666AB80&gt;                      lambda함수의 이름 없이 정의되는 익명 함수로, 한 줄로 간단한 함수를 정의할 때 사용한다.          사용법        \"\"\" lambda 함수에 전달할 매개변수: 함수에서 반환할 값 \"\"\"lambda arguments: expression                    결과        &lt;function &lt;lambda&gt; at 0x000001BF866FEE50&gt;                      numbers = [1, 2, 3, 4, 5]\"\"\"@ lambda : 수행할 연산 정의@ map    : 반복 가능한 객체의 모든 요소에 함수 적용\"\"\"squared_numbers = list(map(lambda x: x**2, numbers))  # 각 요소의 제곱print(squared_numbers)        [1, 4, 9, 16, 25]        enumerate()상위 폴더의 상위 폴더 importAsterisk (*)파이썬에서 코드를 타고 들어가다 보면 *args, **kwargs 와 같은 인자를 볼 수 있다.이는 C언어의 포인터( * )와 헷갈릴 수 있지만 다른 개념이다.여러 요소를 묶어서 하나의 시퀀스로 만들거나,리스트, 튜플, 문자열 등의 시퀀스를 unpacking해서 여러 개의 요소로 분해할 수 있다.*  연산          곱셈      거듭제곱      ndarray 행렬 곱셈        리스트 반복 확장  가변인자 사용  컨테이너 타입 Unpackinghttps://mingrammer.com/understanding-the-asterisk-of-python/# 언패킹numbers = [1, 2, 3, 4, 5]a, b, *rest = numbersprint(a)  # 1print(b)  # 2print(rest)  # [3, 4, 5]a, b, c, d, *e = numbersprint(e)  # [5]# 묶기numbers = [1, 2, 3]new_list = [*numbers, 4, 5]print(new_list)  # [1, 2, 3, 4, 5]**# 딕셔너리 언패킹params = {'param1': 1, 'param2': 2}my_function(**params)  # my_function(param1=1, param2=2)# 키워드 인자 전달def greet(name, age):    print(f\"Hello, {name}! You are {age} years old.\")person_info = {'name': 'Alice', 'age': 30}greet(**person_info)  # Hello, Alice! You are 30 years old.상속super().__init__()데코레이터디스크립터제너레이터단위 테스트unittest"
  },
  
  {
    "title": "병렬(Parallel) 처리",
    "url": "/posts/parallel/",
    "categories": "ML",
    "tags": "ML, Parallel",
    "date": "2023-05-12 00:00:00 +0900",
    





    "snippet": "##  Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups  Multi-GPU 학습 과정https://tutorials.pytorch.kr/beginner/dist_overview.htmlData Parallel Training  Pytorch          DataParallel                  Single-Machine, Multi-GPU                    DistributedDataParallel                  Single-Machine, Multi-GPU          Multi-Machine, Multi-GPU                    import torchimport torch.nn as nnfrom torch.utils.data import DataLoader, Datasetclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.fc = nn.Linear(784, 10)    def forward(self, x):        return self.fc(x)device = torch.device(\"cuda:0\")model = Net()model.to(device)model = nn.DataParallel(model)      criterion모델의 예측값과 실제 타겟 간의 차이를 측정하는 ‘손실 함수(lost function)’ex) 평균 제곱 오차(Mean Squared Error, MSE), 교차 엔트로피 오차(Cross-Entropy Error), …        scatterPytorch에서 tensor의 특정 위치에 값을 할당하는 함수딥러닝에서 iteration 마다 batch를 사용하는 GPU의 개수만큼 나누는 작업    매 iteration마다 Batch를 GPU의 개수만큼 나눈다(scatter).  모델을 각 GPU에 복사하여 할당한다(replicate).  각 GPU에서 foward를 진행한다.  각 GPU에서 input에 대한 출력값이 나오면 이들을 하나의 GPU에 모은다(gather).  하나의 GPU에 모인 값들을 이용하여 loss gradients를 계산한다.  각 GPU로 gradients를 scatter하고 각 GPU에 있는 모델은 계산된 gradient를 가지게 된다.  각 GPU에서 Back-Propagation을 진행한다.  각 GPU에 있는 gradient를 다시 하나의 GPU로 모아서 모델을 업데이트한다.Pytorch 모델 클래스 정의하기  nn.Sequential()로 정의    import torchimport torch.nn as nnfrom torchvision import modelsnum_classes = 5model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)num_ftrs = model.fc.in_featuresmodel.fc = nn.Sequential(    nn.Linear(num_ftrs, 512),    nn.BatchNorm1d(512),    nn.ReLU(inplace=True),    nn.Dropout(),    nn.Linear(512, 256),    nn.BatchNorm1d(256),    nn.ReLU(inplace=True),    nn.Dropout(),    nn.Linear(256, num_classes))        클래스 사용    import torchimport torch.nn as nnimport torchvision.models as modelsresnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)# backbone = nn.Sequential(*list(resnet50.children())[:-1])  # 출력층 사용Xclass CustomResNet(nn.Module):    def __init__(self, resnet50, num_classes):        super(CustomResNet, self).__init__()        self.resnet50 = resnet50        num_ftrs = self.resnet50.fc.in_features        self.linear0 = nn.Linear(num_ftrs, 512)        self.bn0 = nn.BatchNorm1d(512)        self.relu0 = nn.ReLU(inplace=True)        self.dropout0 = nn.Dropout()        self.linear1 = nn.Linear(512, 256)        self.bn1 = nn.BatchNorm1d(256)        self.relu1 = nn.ReLU(inplace=True)        self.dropout1 = nn.Dropout()        self.linear2 = nn.Linear(256, num_classes)    def forward(self, x):        x = self.resnet50(x)        x = self.linear0(x)        x = self.bn0(x)        x = self.relu0(x)        x = self.dropout0(x)        x = self.linear1(x)        x = self.bn1(x)        x = self.relu1(x)        x = self.dropout1(x)        x = self.linear2(x)        return xnum_classes = 5custom_resnet = CustomResNet(resnet50, num_classes)      "
  },
  
  {
    "title": "MLOps (Machine Learning Operations)",
    "url": "/posts/mlops/",
    "categories": "ML",
    "tags": "ML, MLOps",
    "date": "2023-05-11 00:00:00 +0900",
    





    "snippet": "MLOps (Machine Learning Operations)머신러닝 모델의 개발 및 운영 프로세스를 자동화하고 효율화하기 위한 방법‘ModelOps(모델 관리)’ + ‘DataOps(데이터 관리)’ + ‘DevOps(배포, 클라우드)’등장 배경  필요성          주피터 노트북에서 만들어 프로토타입만 사용해본 모델을 실제로 서비스에 이용      파라미터 변경 등으로 인한 모델의 버전 관리      학습에 사용된 데이터셋의 버전 관리      학습에 사용된 데이터와 실제 서비스(Production)에서 받는 데이터가 다른 경우      머신러닝 서버를 올리기 위한 인프라 관리      모델을 다시 학습해야할 필요가 있을 경우        Research 단계에서 Production으로 갈 때 해야 하는 일          API 서버 만들기      모델 관리      데이터셋 관리      ML 인프라 관리      DevOps vs MLOps  DevOps‘소프트웨어 배포’, ‘인프라 운영‘을 중점으로 개발과 운영 프로세스를 통합하는 것이 목표 (CI/CD)(모델에 관여X, 데이터는 개발에서 운영으로 전달만하고 처리X)          버전 관리      컨테이너화      오케스트레이션      로깅      모니터링        MLOps‘데이터 처리‘와 함께 ‘모델을 개발‘하여 ‘실제 환경에서 운영‘하고 모니터링 하는 것까지 목표 (CI/CD/CT)(모델 학습, 서빙 및 관리O, 데이터 처리O)(인프라쪽은 DevOps 팀에 맡기기도 함)          데이터 버전 관리      모델 버전 관리      데이터 파이프라인      모델 서빙      모니터링      On-Premise vs Cloud Computing  온프레미스(On-Premise) 환경          자체적으로 데이터 센터를 운영하여 물리적인 서버, 스토리지, 네트워크 인프라를 직접 보유하고 유지보수 (초기 비용이 많이 발생)      운영체제, 데이터베이스, 응용 프로그램, 보안 소프트웨어 관리 및 업데이트(데이터를 직접적으로 컨트롤해 데이터가 외부에 노출되는 것을 제한할 수 있음)                클라우드 컴퓨팅 (Cloud Computing)서비스 제공 업체가 하드웨어 및 인프라를 관리하고, 사용자는 원격으로 클라우드 서버에 접근하여 리소스를 이용          서비스 제공 형태                  Public Cloud인터넷 접속이 가능한 모든 사용자를 대상으로 서비스          Private Cloud제한된 네트워크 상에서 특정 사용자만을 대상으로 서비스(데이터가 기업 내부에 저장됨)          Hybrid CloudPublic 클라우드와 Private 클라우드를 병행으로 사용하거나,클라우드(가상서버)와 온프레미스(물리서버)를 결합하여 사용하는 방식                          서비스 모델          Infrastructure as a Service (IaaS)인터넷을 통해 가상화된 컴퓨팅 리소스를 제공ex) AWS EC2, MS Azure 가상머신, GCE, …      Platform as a Service (PaaS)서버, 스토리지, 네트워킹같은 인프라를 제공하여, 사용자는 애플리케이션 개발 및 배포만 진행ex) Heroku, Google App Engine, MS Azure App Service, …      Software as a Service (SaaS)인프라, 애플리케이션 코드, 데이터를 공급자가 모두 관리하여 제공ex) MS Office 365, Google Workspace, …          데이터(Data) 소프트웨어데이터 수집 파이프라인데이터 수집, 전처리, 로깅 등  Apache Sqoop  Apache Flume  Apache Kafka  Flink  Spark Streaming  Airflow데이터 저장  RDBMS          MySQL        분산 저장          Hadoop        오브젝트 스토리지          Amazon S3      MinIO      데이터 관리  데이터의 벨리데이션 체크          TFDV        데이터 버전 관리          DVC        피처 스토어          Feast      Amundsen      모델(Model) 소프트웨어모델 개발  모델 개발을 격리된 환경에서 수행          Jupyter Hub      Docker      Kubeflow        하이퍼파라미터 옵티마이제이션 같은 병렬 학습을 클라우드 환경에서 쉽게 할 수 있게 해주는 툴          Optuna      Ray      katib      모델 버전 관리  소스 코드 형상 관리          Git        모델의 소스 코드 뿐만 아니라 패키징된 형태의 모델과 사용한 하이퍼 파라미터, 모델의 성능 매트릭까지 모두 함께 기록          MLflow        CI/CD          Github Action      Jenkins      Travis CI      모델 학습 스케줄링 관리GPU 인프라 관리, 모델 학습 스케줄링  모니터링          Grafana        스케줄러          Kubernetes      서빙(Serving) 소프트웨어데이터를 받으면 ML 모델에 predict 함수를 부른 다음 그 결과값을 반환하는 행위를 사용자가 직접 코드를 돌려보는 것이 아닌 서버에서 API 형태로 제공하는 서비스모델 패키징OS나 특정 python 패키지에 의존성이 없도록 컨테이너 혹은 VM 기반으로 패키징  ML 모델에 특화된 API 서빙 프레임워크          Flask      FastAPI      BentoML      Kubeflow      TFServing      KFServing      seldon-core      서빙 모니터링서빙 후 환경이 제대로 돌아가고 있는지 모델의 성능이 떨어지고 있지는 않은지와 같은 매트릭을 지속적으로 모니터링하고 문제가 생기면 알림을 받는 것을 자동화  Prometheus  Grafana  Thanos파이프라인 매니징서빙 시 모델의 성능이 떨어지면 이전 모델로 롤백하거나 AB 테스팅을 하는 등 성능 확인을 위해서 이전 모델 학습과정 전체를 다시 돌려보고 싶은 경우를 위해 모델 개발 단계부터 단순한 파이썬 코드가 아닌 특정한 파이프라인 코드로 개발을 해야 재사용이 가능  Kubeflow  argo workflow  AirflowSaaS (Software as a Service) 제품  (Amazon Web Services) AWS SageMaker  (Google Cloud Platform) GCP Vertex AI  (Microsoft Azure) Azure Machine Learning데이터 관리  Apache Hadoop  Apache Spark모델 개발  Tensorflow  Pytorch버전 관리  Git  Github, Gitlab, BitbucketCI/CD  Jenkins  CircleCI, Travis CI, Gitlab CI/CD컨테이너화 오케스트레이션  Docker  Kubernetes모델 서빙 및 배포  Kubeflow  Amazon SageMaker로그 및 모니터링  Prometheus  Grafana  ELK stack (Elasticsearch, Logstash, Kibana)보안 및 권한 관리  Kubeflow Identity and Access Management (IAM)  Vault데이터 모니터링 및 관리  Apache Airflow  Apache Kafka자동화 플랫폼  MLflow  Terraform"
  },
  
  {
    "title": "데이터 증대(Augmentation)",
    "url": "/posts/augmentation/",
    "categories": "ML",
    "tags": "ML, Augmentation",
    "date": "2023-03-27 00:00:00 +0900",
    





    "snippet": "데이터 증대      Pytorch 라이브러리      import torch  import torchvision  import torch.nn as nn  import torch.optim as optim  import torch.nn.functional as F  from torch.optim import lr_scheduler  from torchvision import models, transforms  from torchvision.datasets import ImageFolder  from torch.utils.data import TensorDataset, DataLoader, Dataset                데이터 transforms 정의    train_transforms = transforms.Compose([    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),    transforms.RandomRotation(degrees=15),    transforms.RandomHorizontalFlip(),    transforms.CenterCrop(size=224),    transforms.ToTensor(),    transforms.Normalize(mean=[0.485, 0.456, 0.406],                        std=[0.229, 0.224, 0.225])])test_transforms = transforms.Compose([    transforms.Resize(size=256),    transforms.CenterCrop(size=224),    transforms.ToTensor(),    transforms.Normalize(mean=[0.485, 0.456, 0.406],                        std=[0.229, 0.224, 0.225])])        위의 코드는 이미지 분류 모델을 학습하기 전에 데이터를 증강하기 위한 transform을 정의한 것이다.(Test 데이터에서는 Rotation이나 Flip을 수행하지 않았다.)        데이터 로드    batch_size = 32train_dataset = CustomDataset(train_df, transform=train_transforms)train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)test_dataset = CustomDataset(test_df, transform=test_transforms)test_loader = DataLoader(test_dataset, batch_size=batch_size)        transform은 원본 이미지에 영향을 주지 않고 수행되며,이 기법을 사용해서 1회 epoch에 입력되는 이미지 수가 변하는 것은 아니지만,    훈련 중에 epoch마다 원본 이미지를 랜덤하게 변환시킴으로써 전체 학습 과정에서는 마치 원래 가지고 있던 이미지들 보다 더 다양한 이미지로 학습한 것과 같은 효과를 얻을 수 있어 모델의 일반화 성능에 도움을 준다.        Transfer Learning 모델    num_classes = 5model = models.resnet50(weights='DEFAULT')num_ftrs = model.fc.in_featuresmodel.fc = nn.Sequential(    nn.Linear(num_ftrs, 512),    nn.BatchNorm1d(512),    nn.ReLU(inplace=True),    nn.Dropout(),    nn.Linear(512, 256),    nn.BatchNorm1d(256),    nn.ReLU(inplace=True),    nn.Dropout(),    nn.Linear(256, num_classes))model.to(device)# define optimizeroptimizer = optim.Adam(model.parameters(), lr=learning_rate)scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)        사전 훈련된 ‘ResNet50’에 추가로 레이어를 이어 모델 정의          Dropout과적합을 방지해서 모델의 일반화 성능을 향상시키기 위해 사용하는 dropout은기본적으로 Pytorch와 같은 프레임워크에서 model.train()으로 training 과정에서는 수행하고, model.eval()으로 inference 과정에서는 수행되지 않도록 동작한다.            Fine-Tunning    for i, data in enumerate(train_loader):    inputs, labels = data    inputs, labels = inputs.to(device), labels.to(device)            # zero the parameter gradients    optimizer.zero_grad()    # forward + backward + optimize    outputs = model(inputs)    loss = criterion(outputs, labels)    loss.backward()    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)    optimizer.step()      "
  },
  
  {
    "title": "전이 학습(Transfer Learning)",
    "url": "/posts/transfer_learning/",
    "categories": "ML",
    "tags": "TransferLearning",
    "date": "2023-03-19 00:00:00 +0900",
    





    "snippet": "  참고자료          나동빈님 전이학습 설명 유튜브논문 이해에 필요한 배경 지식과 이미 익숙한 사람이라면 스킵할만한 부분도 꼼꼼하게 설명해주신다.      전이 학습(Transfer Learning)소개      Big Transfer(BiT) 논문Google Research 팀에서 발표한 이 논문은 이미지 분류를 목적으로 작은 데이터셋만으로도 좋은 성능의 모델을 쉽게 얻어낼 수 있는 방법에 대해서 작성되었다.    대상의 표현적인 정보를 흔히 ‘Representation’ 또는 ‘Semantic Feature’라고 말하는데, ‘Representation Learning’은 이미지나 텍스트와 같은 데이터셋에 존재하는 feature들을 학습하는 것이다.    신경망의 깊이가 깊어지면 서로 다른 종류의 복합적인 feature들을 추출해낼 수 있다.신경망의 낮은층에서 학습되는 특징인 low-level feature에서는 주로 색의 변화나 경계의 방향에 대한 정보가 추출되고,깊은 층에서 학습되는 특징인 high-level feature에서는 주로 객체의 패턴이나 형태 정보를 추출할 수 있다.              전이 학습이 필요한 이유좋은 성능의 모델을 만들기 위해서는 양질의 많은 데이터셋이 필요하고, 수집한 데이터셋으로 큰 리소스를 들여 설계한 모델을 처음부터 학습시켜야 한다.Google과 같은 큰 기업에서는 이러한 과정이 가능하겠지만 개인이나 작은 기업의 경우에는 양질의 데이터를 대량으로 수집하는 것부터가 쉽지 않다.이러한 한계를 극복하면서 좋은 성능의 모델을 효율적으로 개발하기 위한 아이디어로 전이학습(Transfer Learning) 을 사용할 수 있다.전이 학습 방법Transfer Learning은 네트워크의 인코더 부분에 적용해서 사용한다.  먼저 사전에 대량의 데이터로 학습된(pre-trained) 모델을 불러온다.  (여기서 pre-trained 모델은 이미지 처리의 경우 CNN모델이 될 수 있고 자연어 처리에서는 BERT 같은 모델이 사용될 수 있다.)  입력 데이터에 맞게 네트워크의 Input shape을 조정한다.  전이할 Feature Extractor Layer 부분을 초기 가중치로 재활용하여 네트워크를 구성한다.  이 네트워크의 마지막에 새로운 Fully Connected Layer를 필요한 Output shape에 맞게 구성하여 이어붙인다.  재구성한 네트워크를 학습한다.pre-trained 모델에서 진행된 사전에 이루어진 학습을 ‘업스트림(upstream)‘이라고 하고, 사전 모델을 전이해서 새롭게 진행하는 학습은 ‘다운스트림(downstream)‘이라고 한다.(다운스트림은 일반적으로 과하지 않은 epoch 수에 많지 않은 데이터셋으로 높은 정확도를 얻을 수 있기 때문에 비용이 적게 든다.)    다운스트림은 전이된 네트워크 부분의 가중치를 학습시키지 않는 ‘프리징(Freezing)‘과 전체 네트워크를 모두 학습시키는 ‘파인튜닝(Fine-Tuning)‘으로 나뉜다.  프리징현재 데이터셋에 대한 오버 피팅으로 부터 비교적 안전하다.            파인튜닝일반적으로 많이 사용되는 방식미세조정만 하기 때문에 일반적인 학습보다 학습률을 낮게 설정한다.                          원샷러닝(One-shot Learning)하나의 데이터로 학습하여 식별할 수 있는 모델을 만드는 방식의료 분야처럼 하나의 데이터를 수집하는 것이 비용이 크거나 희귀한 경우 사용                    퓨샷러닝(Few-shot Learning)몇 개의 데이터로 학습을 진행하는 방식            전이 학습의 장점  어느 정도 훈련된 가중치를 가지고 학습을 시작하므로 최종 수렴에 도달하는 속도가 빨라질 수 있다.  사전에 학습된 네트워크와 새로 학습시킬 네트워크가 완전히 동일한 목적의 태스크가 아니더라도 두 데이터셋이 유사한 특징을 가진다면 정확도가 향상될 수 있다.(ex. 50개 클래스의 꽃 분류 모델에서 10개 꽃 분류 모델로 전이 학습)  가지고 있는 데이터셋의 크기가 작더라도 모델이 좋은 성능을 내도록 학습할 수 있다.다른 태스크의 Feature Extractor Layer가 긍정적인 영향을 미치는 이유는?사용할 데이터셋의 조건이 pretrain할 때의 데이터셋과 동일하다면 모델을 그대로 가져와서 재학습하는 것이 이상하지 않지만,조건에 차이가 있는 경우에도 Feature Extractor Layer를 전이학습에 사용한다.그 이유는, 대량의 데이터로 얕지 않은 신경망을 사용하여 학습했기 때문에네트워크가 보편적인 이미지 종류에 대한 feature를 추출하는 쪽으로 학습되어유의미한 가중치를 가지게 되고 결과적으로 좋은 모델이 만들어진다.전이 학습 예제Transfer Learning으로 CNN 사용  ResNet-50을 이용하여 모델 구성    model = Sequential()model.add(ResNet50(include_top=False, pooling='max', weights=RESNET_WEIGHTS_PATH))model.add(Dense(NUM_CLASSES, activation='softmax'))# ResNet-50 model is already trained, should not be trainedmodel.layers[0].trainable = True        모델을 ResNet-50으로 초기화하고 마지막에 원하는 클래스들로 분류하도록 softmax를 활성화함수로 사용하는 Dense 레이어를 추가하여 간단한 전이 학습 모델을 구성    모델 컴파일    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])model.summary()        _________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================resnet50 (Model)             (None, 2048)              23587712  _________________________________________________________________dense (Dense)                (None, 2)                 4098      =================================================================Total params: 23,591,810Trainable params: 23,538,690Non-trainable params: 53,120_________________________________________________________________          BiT 논문Pre-Training 실험  데이터셋          BiT-S (약 1,300,000개 이미지의 ILSVRC-2012)      BiT-M (약 14,000,000개 이미지의 ImageNet-21K)      BiT-L (약 300,000,000개 이미지의 JFT-300M)        네트워크 아키텍처          ResNet-50x1 (레이어 50, 너비 1)      …      ResNet-152x4 (레이어 152, 너비 4)(너비 width의 증가는 블록 내 필터 수의 증가)      Upstream / Pre-Training정규화 기법입력되는 feature들에 따라서 스케일의 분포 정도가 다를 경우 각각의 분산, 평균에 차이가 생긴다.(ex. 나이는 입력이 주로 0에서 100내외이지만 시력은 입력이 0 내외로 들어옴)입력되는 데이터들마다 mean, variance와 같은 통계적 특성(Statistics)이 다르면 학습의 난이도가 어려워질 수 있다. 이를 방지하기 위한 기법으로 input 전에 정규화를 진행하곤 한다.(이미지의 경우 Input Layer 전에 RGB채널마다 정규화를 진행해서 각각의 픽셀들이 평균이 0 표준편차가 1이 되도록 조정)배치 정규화(Batch Normalization)Input Layer 뿐아니라 Hidden Layer에 입력하기 전에도 정규화를 진행      효과          입력데이터의 분포가 안정되어 훈련 과정이 안정되고 학습 속도가 빨라진다.      모델의 최종 성능이나 수렴에 큰 영향을 미치는 가중치 초기화에 덜 민감하다.      과적합을 억제하는 효과가 있어 모델이 일반화된다.      그래디언트 소실 또는 폭주 문제를 완화해서 깊은 신경망 훈련에 도움을 준다.      학습할 데이터 양이 많기 때문에 전체 데이터셋을 배치 사이즈로 분배하고 이를 다시 GPU와 같은 디바이스들끼리 분담하여 처리하는 방법을 사용하는데,모델이 큰 경우 디바이스당 요구되는 메모리가 크기 때문에 일반적으로 한번에 작은 데이터를 입력 받는다.이로 인해 모든 디바이스마다 계산한 Statistics 값들을 수합하면 동기화하는 비용이 더 커지게 되면서 지연될 수 있고,배치 사이즈가 작으면 배치의 평균과 분산이 iteration마다 달라져 BN이 가진 배치의 통계 값이 전체 데이터셋을 대표한다는 가정에 어긋나면서 정확도 하락으로 이어질 수 있기 때문에 BiT 논문에서는BN Layer를 사용하지 않는다.    대신 몇 개의 채널에 대한 피처를 묶어서 정규화하는 방법으로 Layer Norm과 Instance Norm의 장점을 적절히 사용한 ‘Group Normalization(GN)’과 가중치를 표준화하는 ‘Weight Standardization(WS)’를 함께 사용하여 배치 사이즈로 인해 발생할 수 있는 문제를 개선하고 성능을 향상시켰다.(배치 사이즈에 의해 성능이 좌우되지 않기 때문에 배치 사이즈를 키울 수 있고 덕분에 학습 속도가 향상됨)      가중치 표준화(Weight Standardization)표준편차가 1이 되도록 레이어의 가중치를 정규화하는 것데이터 전처리  224 x 224로이미지를 resize 한 후, 정사각형으로 만듦  Crop out으로 이미지에서 원하는 부분을 잘라냄  무작위로 좌우 반전시켜 데이터 증대  (인간의 눈으로 보았을 때 좌우 반전은 sementic한 정보가 크게 바뀌지 않으므로 상하 반전은 잘 사용하지 않고 좌우 반전을 사용)                   Pre-training      Fine-tuning                  Weigth Decay      O      X              MixUp      X      O        가중치 감쇠(Weight Decay)손실 함수에 패널티로 정규화 항($l_2$ norm)을 추가 손실 항목으로 더하여 신경망의 과적합을 방지하는 정규화 기술  MixUp데이터 증강(Data Augmentation) 기법 중 하나로,두 샘플데이터를 한 쌍으로 데이터와 라벨을 혼합해 새로운 합성 데이터, 새로운 합성 라벨을 만들고 이를 훈련에 사용하여 과적합을 방지하는 기술BiT에서는 사전 학습에 Weight Decay로 정규화를 수행하고 데이터가 많으므로 MixUp을 하지 않았다.또한, 배치 사이즈를 4096으로 하여 512개의 칩을 가지고 있는 TPUv3-512에 칩마다 8개의 이미지가 들어가도록 진행하였다.(SGD momentum 0.9, 초기 learning rate 0.03으로 세팅하고학습률을 점진적으로 줄여나가는 learning rate decay 사용)Downstream / Fine-TuningSGD momentum 0.9, 초기 learning rate 0.003에 learning rate decay 사용(Pre-training 과정에서 학습되었던 가중치가 많이 변하는 것을 방지하기 위해 Fine-tuning 과정에서는 learning rate을 상대적으로 작은 크기로 사용함)medium과 large 태스크에서 $α$ = 0.1로 MixUp 진행            task      step                  small 태스크 (20k개 미만)      500 steps              medium 태스크 (500k개 미만)      10,000 steps              large 태스크      20,000 steps        step각 미니배치마다 한번씩 수행되는 모델의 가중치 업데이트  epoch모든 미니배치를 처리하여 전체 데이터셋을 1회 학습하는 것실험 결과    데이터가 적을 때 많은 성능 차이를 보이며, 기존의 SOTA 보다 높은 정확도를 보여줌      Specialist해당 태스크만을 목적으로 pre-trained representations를 이용  Generalist일반적인 목적으로 pre-trained representations를 이용  Baseline일반적으로 많이 사용되는 사전 학습 모델    ResNet-152x4 처럼 아키텍처가 크면 데이터셋의 크기가 클 수록 Downstream 태스크에서 정확도가 향상됨    Upstream 과정에서는 라벨링된 데이터만으로 학습이 되었다는 점이 차이가 있지만,학습 데이터가 적은 상황에서 기존에 제안된 준지도학습(Semi-Supervised Learning, SSL) 방법들보다 높은 정확도를 보임    Object Detection에서 BiT를 Backbone Network로 사용할 때 정확도가 개선됨        모델의 크기가 작을 경우, 데이터셋의 크기가 커짐에 따라 오히려 정확도가 감소할 수 있음    큰 데이터셋으로 학습할 경우 학습 시간을 충분히 사용하여 진행해야하며,짧은 시간마다 learning rate decay를 수행하기 시작하면 최종 성능이 떨어질 수 있음높은 weight decay를 사용했을 때 수렴 속도가 느려진 대신 최종 성능이 좋아짐"
  },
  
  {
    "title": "배치 정규화(Batch Normalization)",
    "url": "/posts/batch_normalization/",
    "categories": "ML",
    "tags": "ML, Batch, Normalization",
    "date": "2023-03-17 00:00:00 +0900",
    





    "snippet": "  참고자료          나동빈님 배치 정규화 설명 유튜브딥러닝 아키텍처에서 BN의 동작에 대해 관련 논문과 함께 꼼꼼히 들을 수 있다.      배치 정규화 (Batch Normalization)초기 Input Layer에 들어오는 데이터 외에 Hidden Layer에 입력되는 데이터에도 정규화를 진행하여 성능을 개선  논문          Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift배치 정규화 제안      How Does Batch Normalization Help Optimization?배치 정규화가 도움이 되는 진짜 이유      입력 데이터 전처리 방법표준화 (Standardization)입력 데이터가 mean = 0, variance = 1인 표준 정규분포 $N(0, 1)$를 따르도록 표준화하는 것  $$ x_{std} = \\frac{x - μ}{σ} $$  ( $μ$ : 평균, $σ$ : 표준편차 )      최댓값과 최솟값에 제한이 없으므로 특정 범위를 벗어난 데이터를 outlier로 보고 제거하는 데에도 사용할 수 있다.    정규화 (Normalization)입력 데이터의 값들을 0~1 또는 -1~1과 같은 범위의 값으로 정규화하는 것(ex. 이미지가 가지고 있는 0~255의 픽셀 값을 0~1의 값으로 스케일링)  $$ x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}} $$      입력 데이터의 값들이 특정 방향으로 치우쳐진 분포를 가지고 있으면큰 learning rate을 사용할 경우 분산이 작은 방향에서 학습이 제대로 이루어지지 않을 수 있고,learning rate을 작게 설정해도 학습 과정에서 많은 단계를 거쳐야 하기 때문에 시간이 오래 걸린다.이를 개선하기 위해 각 차원에 있는 값들의 범위가 비슷해지도록 ‘정규화’를 수행하면,데이터의 분산이 고르게 변화하여 상대적으로 큰 learning rate을 사용해도 최적의 성능에 쉽게 도달할 수 있다.결과적으로, 학습률을 높일 수 있으므로 학습 속도가 빨라지는 효과를 볼 수 있다.    화이트닝 (Whitening)평균이 0이고, 공분산이 단위 행렬인 정규분포 형태의 데이터로 변환하는 기법(공분산이 단위 행렬 : 서로 다른 feature들 사이에 연결성이 없는 Decorrelated 형태로 데이터를 전처리)  특이값 분해(Singular Value Decomposition, SVD)와 같은 기법을 통해 전체 데이터에 대해 새로운 축을 찾음  새로운 축으로 전체 데이터를 transformation하여 각각의 축에 대해 correlation이 적은 형태로 만듦  특정 범위의 값을 가지면서 평균 값이 0이 되도록 전처리    (PCA나 화이트닝 보다 간단하게 좋은 성능을 낼 수 있는 정규화가 많이 사용됨)배치 사이즈 개수 만큼의 x를 입력 받음"
  },
  
  {
    "title": "배치(Batch)",
    "url": "/posts/batch/",
    "categories": "ML",
    "tags": "ML, Batch",
    "date": "2023-03-15 00:00:00 +0900",
    





    "snippet": "배치(batch) 관련 내용 정리헷갈리는 배치와 미니배치에 대한 개념과 학습할 때 보통 배치 사이즈를 정하는데 왜 사용하는지, 어떻게 진행되는건지에 대한 정리를 해보려고 한다.배치(Batch)전체 데이터셋을 일정한 크기의 묶음(batch)으로 나누는 것주어직 작업에 대한 데이터를 일괄 처리하기 위해 사용하며, 데이터를 몇 개씩 묶어서 학습할 것인지가 배치 사이즈가 된다.데이터를 1개씩 입력받아 매번 연산하는 것보다 한번에 n개의 데이터를 묶음으로 입력 받아 연속으로 연산을 진행하면 중간중간에 I/O를 통해 데이터를 읽어오면서 느려지는 횟수를 줄여 효율적이고 빠르게 학습시킬 수 있다.단순한 모델에 적은 데이터를 학습시키는 경우 그냥 학습해도 큰 문제가 되지 않지만, 신경망의 깊이가 깊어지고 노드 수가 많아짐에 따라 연산량이 급격히 증가하게 되면서 한번 학습을 완료하는데 너무 많은 시간이 소요될 수 있다.   모델을 설계하고 성능을 테스트 해보는 과정에서 몇번의 학습이 수행될지 모르는데 가능하면 빠르게 끝내는 것이 좋을 것이다.미니배치(Mini-Batch)데이터셋의 묶음 하나각 미니배치에 포함된 데이터의 개수가 미니배치 사이즈로 배치 사이즈에 의해 결정된다. (배치 사이즈와 동일)따라서 전체 데이터 수를 미니배치 사이즈로 나눈 수가 미치배치의 개수이다.일반적으로 미니배치 사이즈를 32, 64, 128 등 2의 제곱수로 설정하면 GPU에서의 연산이 최적화된다. 학습의 안정성이나 수렴 속도를 고려해 적절하게 조절한다.미니배치 학습전체 데이터셋을 작은 배치로 나누어 각 미니배치를 사용해 학습하는 방식데이터를 하나씩 입력시킬 경우, 신경망을 한번 학습시키는데 걸리는 시간이 짧지만 전체 학습에 대한 시간은 길어지고 각각의 그래디언트가 상당히 불안정해 데이터의 작은 변동에도 학습에 큰 영향을 미쳐 노이즈에 민감해진다. 또한 최적의 가중치 값을 찾는 과정에서 국소적인 최솟값(local minimum)에 빠져 전역 최솟값(global minimum)으로 가지 못하고 헤매는 일이 자주 발생할 수 있다.반면에 전체 데이터셋을 한번에 입력시킬 경우, 학습을 완료하는데 걸리는 시간을 단축할 수 있지만 신경망을 한번 학습시키는데 걸리는 시간이 매우 길어진다.따라서 전체 데이터셋을 한번에 처리하는 ‘배치 학습(Batch Learning)’과 전체 데이터를 하나의 데이터 포인트로 간주해 가중치를 업데이트하는 ‘확률적 경사하강법(SGD)’을 결합한 미니 배치 학습을 이용하면 전체 데이터를 모두 반영하면서 장점을 가져올 수 있다.↪ 미니배치를 사용하면 학습에 좋은 이유배치 사이즈를 n으로 설정해 미치배치 하나에 n개의 데이터가 들어있는 경우 전체 데이터셋에 대한 메모리가 아닌 미니배치 크기만큼의 메모리만 요구되기 때문에 메모리 요구량이 줄어든다.또한, 학습 알고리즘의 성능과 학습 시간을 조절할 수 있다.↪ 미니배치 학습 과정  전체 데이터셋을 배치 사이즈의 데이터를 가진 미니배치들로 나눈다.  각 미니배치를 순차적으로 가져온다.  해당 미니배치에 있는 데이터로 손실함수를 계산한다.  손실함수의 그래디언트(도함수)를 계산한다.  계산된 그래디언트를 사용하여 가중치를 업데이트한다.한 미니배치에 대한 처리가 완료될 때마다 가중치를 업데이트하며, 이전 미니배치에서 가중치 결과는 다음 미니배치의 처리에 영향을 미친다.결과적으로 학습 중에 가중치가 지속적으로 조정이 되며, 전체 데이터에 적합하게 학습이 완료된다.↪ 병렬로 미니배치 학습을 하면 한번에 나오는 그래디언트들을 어떻게 할까?미니배치 내에서의 연산은 GPU에서 병렬로 이루어지지만 가중치 업데이트는 미니배치 하나가 처리될 때마다 이루어진다. 동시에 여러개의 미니배치가 처리되었다고 하더라도 가중치 업데이트는 순차적으로 진행된다.↪ CPU에서 미니배치 학습을 해도 상관없을까?미니배치 학습은 하드웨어 리소스와 독립적이기 때문에 CPU에서도 미니배치 학습은 가능하지만 시간이 오래걸리고 GPU를 사용할 경우 여러 코어를 사용해 병렬 처리가 가능하므로 대규모 데이터나 복잡한 연산에 이점이 있다.↪ 60000개 데이터셋에 배치 사이즈가 100일 경우  전체 데이터셋 크기 : 60000  배치 사이즈(각 미니배치의 크기) : 100  미니배치 개수 : 600에폭(Epoch)SGD배치 정규화(Batch Nomalization)  문제점          Internal Coveriate Shift네트워크의 각 레이어를 통과할 때마다 입력 분포가 변하는 현상입력 분포가 변화함에 따라 학습이 어려워지고 수렴 속도가 늦어지게 되는 문제가 발생할 수 있다.      Vanishing Gradients신경망의 각 레이어를 통과할 때마다 그래디언트가 사라지는 현상      주로 합성곱 신경망(CNN)이나 완전 연결 신경망(Fully Connected Neural Networks)에서 사용되어 성능을 향상 시킨다."
  },
  
  {
    "title": "모델의 성능 확인",
    "url": "/posts/model_performance/",
    "categories": "ML",
    "tags": "ML, Model",
    "date": "2023-03-08 00:00:00 +0900",
    





    "snippet": "  모델                  선형(Linear) 모델그래프의 형태가 1개의 직선(1차 방정식)으로 표현되는 모델(1개의 일정한 기울기를 가짐)                    비선형(NonLinear) 모델그래프의 형태가 1개의 직선(1차 방정식)으로 표현되지 않는 모든 형태의 모델(1개 보다 많은 기울기를 가져 임의의 조건에 의해 기울기가 변함)              평가‘손실함수’와 ‘척도’의 개념은 유사하지만 경우에 따라 선택해서 모델을 최적화하는데 사용한다.                  손실 함수(Loss Function)학습 중에 모델의 성능을 향상시키기 위해 참조하는 값‘목적 함수(Objective Function)’ 또는 ‘비용 함수(Cost Function)’, ‘에너지 함수(Energy Function)’라고 부르기도 함옵티마이저에서 가중치를 업데이트할 때, 모델이 얼마나 잘못 예측하는가를 나타내는 손실 점수로 학습(training)의 방향을 모니터링 해볼 수 있으며, 이 값을 최소화하는 것을 목적으로 모델을 최적화 한다.ex) 평균제곱오차(MSE), 평균절대오차(MAE)                    척도(Metrics)학습된 모델을 평가하기 위해서 사용하는 값모델의 성능을 숫자로 표현하여 다른 모델과 비교한다.ex) 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-Score            모델 성능 확인평균제곱오차(MSE, Mean Squared Error)실제 값과 모델이 예측한 값의 차이를 제곱한 값들의 평균E = (1/n) * n_sigma_i=1(y_i - y’_i)^2Accuracy의 개념을 적용하지 않는 회귀 모델에 대한 손실 함수로 많이 사용된다.평균절대오차(MSE, Mean Absolute Error)실제 값과 모델이 예측한 값의 절대 오차E = (1/n) * n_sigma_i=1|y_i - y’_i|Accuracy의 개념을 적용하지 않는 회귀 모델에 대한 지표로 많이 사용된다.혼동 행렬(Confusion Matrix)Confusion Matrix에 작성된 숫자는 변하지 않지만 클래스마다 TP, TN, FP, FN은 다시 정해진다.    Confusion Matrix의 (1,1)을 Class 1의 관점에서 보면 정답과 모델의 예측 결과가 같으므로 TP가 되지만, Class 2의 관점에서 보면 정답에도 속하지 않고 모델의 예측에도 속하지 않아 해당 클래스와 무관하므로 TN이 된다.  TP(True Positive) - 정탐실제로 양성 클래스이고, 분류 모델에서 양성으로 올바르게 예측한 수  TN(True Negative) - 일반실제로 음성 클래스이고, 분류 모델에서 음성으로 올바르게 예측한 수  FP(False Positive) - 오탐실제로는 음성 클래스이고, 분류 모델에서 양성으로 잘못 예측한 수  FN(False Negative) - 미탐실제로는 양성 클래스이고, 분류 모델에서 음성으로 잘못 예측한 수```pythonfrom sklearn.metrics import confusion_matrixlabel = [1, 2, 1, 2, 3, 2, 4, 2, 3, 4, 1]pred = [1, 2, 1, 3, 3, 2, 1, 1, 2, 2, 3]print(confusion_matrix(label, pred))```shell  [[2 0 1 0] [1 2 1 0] [0 1 1 0] [1 1 0 0]]정확도(Accuracy)Accuracy = number of correct predictions(올바르게 예측한 수) / number of total predictions(전체 예측 수) = (각 클래스의 TP) / (TP + TN + FP + FN)데이터셋의 클래스들이 동일한 분포를 갖고 있다면 Accuracy(정확도)를 유용한 평가지표로 사용할 수 있다.(100장의 이미지 데이터셋에 고양이 이미지 50장, 호랑이 이미지 50장이 있다면 equal distribution을 갖고 있는 데이터셋)정밀도(Precision)분류 모델이 특정 클래스로 예측한 것 중에서 실제로 해당 클래스인 것의 비율(Confusion Matrix의 각 열을 통해 특정 클래스에서 분류 모델이 얼마나 올바르게 예측하는지를 볼 수 있다.)Precision = TP / (TP + FP)(0.0 ~ 1.0 사이의 값을 가지며 높을수록 좋음)FP(오탐)가 0일 경우 정밀도는 1.0이 된다.재현율(Recall)(Sensitivity)(Confusion Matrix의 각 행을 통해 특정 클래스일 때 분류 모델이 주로 어떤 클래스로 예측하는지를 볼 수 있다.)Recall = TP / (TP + FN)(0.0 ~ 1.0 사이의 값을 가지며 높을수록 좋음)FN(미탐)이 0일 경우 재현율은 1.0이 된다.불균형 데이터(Imbalanced data)데이터셋의 클래스들이 불균형한 경우에 Accuracy는 좋은 평가지표(Metrics)로 작용하지 못할 수 있다.만약 데이터셋이 고양이 이미지 5장, 호랑이 95장으로 이루어져 있고, output을 무조건 호랑이 클래스로 분류하도록 모델을 개발한 후, Accuracy를 계산해보면 이 모델은 95%의 좋은 성능을 가진 것으로 평가된다. 하지만 이 모델을 실제로 배포하여 사용해보면 길고양이들도 전부 호랑이로 판단해버리는 문제가 발생할 것이다.F1 ScorePrecision과 Recall의 조화평균데이터가 불균형할 때 분류 모델에서 사용되는 머신러닝 평가지표(Metrics)이다.F1-Score = 2 * (Precision * Recall) / (Precision + Recall)Hanley &amp; McNeil’s auc comparison methodDeLong 방법으로도 알려졌으며, 두 가지 다른 진단 또는 예측 모델의 ROC 곡선(AUC) 아래 영역을 비교하는데 사용되는 통계적 접근 방식AUC 값은 두 모델을 비교할 때 식별력의 척도를 보여주지만 통계적 불확실성(분산)이 해석에 영향을 줄 수 있으므로 AUC 값을 직접 비교하는 것만으로는 충분하지 않을 수 있기 때문에 두 AUC 값의 차이가 통계적으로 유의한지 확인하기 위한 통계 테스트이다.  AUC 계산성능 메트릭을 사용하여 두 모델의 AUC 값 계산  분산 계산AUC에 대한 분산 계산  공분산 계산AUC에 대한 공분산 계산  Z-통계량 계산AUC, 분산, 공분산을 통해 계산하여 두 AUC 간의 차이가 0에서 얼마나 많은 표준 편차가 있는지를 나타낸다.Z-statistic이 0.05처럼 0에 가까울 경우 두 모델 간의 AUC 차이가 임의의 기회로 인한 것이 아닐 가능성이 높고 -4.3처럼 0에서 상당한 차이가 있는 경우 음의 값이므로 첫번째 모델이 두번째 모델보다 성능이 훨씬 나쁘며"
  },
  
  {
    "title": "모델 추론(Inference)",
    "url": "/posts/inference/",
    "categories": "ML",
    "tags": "Inference",
    "date": "2023-03-02 00:00:00 +0900",
    





    "snippet": "추론(Inference)모델을 학습시키고 나서는 실제 적용할 곳에 런타임에서 돌려줘야 함ONNX(Open Neural Network Exchange)Pytorch나 Tensorflow 등의 다른 프레임워크 간의 상호 운용을 허용하여 원활하게 교환하고 배포할 수 있게 해주는 표준 파일 형식사전 훈련된 모델을 ONNX 형식으로 내보내면 ONNX를 지원하는 다른 프레임워크에서 가져와 다양한 환경에서 사용할 수 있다.Inference RuntimeTFLite-RTONNX-RT(ONNX Runtime)ONNX가 모델을 표현하고 교환하는 것을 처리 동안에 ONNX 연산자의 최적화된 구현을 제공하고 계산을 병렬화하여 효율적인 ONNX 모델을 실행 및 추론하는 엔진TVM compilerApache에서 개발한 딥러닝 컴파일러로 모델을 타겟 디바이스에서 최적의 속도와 정확도를 낼 수 있는 코드 변환 작업 도구다양한 프레임워크로 부터 모델을 통합된 형태로 컴파일통합된 모델을 타겟 하드웨어에 최적화된 형태로 실행모델 컴파일러TensorflowTensorflow에서는 그래프 기반 컴파일러를 사용한다.모델을 그래프 형태로 변환하고 최적화하여 실행 속도를 향상시키는 역할을 한다.PytorchPytorch는 동적 그래프 컴파일러를 사용한다.모델을 실행하면서 그래프를 생성하고 최적화하는 방식으로 동작한다.디버깅과 실험하기에 더 편리하다.CaffeONNX(Open Neural Network Exchange)모델의 컴파일이나 서로 다른 딥러닝 프레임워크 간에 모델 변환을 위한 표준으로 다양한 딥러닝 프레임워크 간에 모델을 공유하고 실행하기 위한 중간 표현을 정의한다.ONNX를 지원하는 프레임워크에서는 ONNX 모델을 해당 프레임워크의 네이티브 형식으로 컴파일할 수 있다.TVM(Apache TVM)오픈 소스 컴파일러 및 실행 엔진으로 딥러닝 모델을 최적화된 코드로 컴파일하고 다양한 하드웨어에서 실행할 수 있도록 지원한다.CoreML(Apple Core Machine Learning)iOS나 macOS에서 머신러닝 모델을 실행하기 위한 프레임워크인 CoreML은 모델을 컴파일하고 모바일에서 실행하기 위한 도구를 제공한다.##ONNX(Open Neural Network Exchange)Pytorch나 Tensorflow 등의 다른 프레임워크 간의 상호 운용을 허용하여 원활하게 교환하고 배포할 수 있게 해주는 표준 파일 형식사전 훈련된 모델을 ONNX 형식으로 내보내면 ONNX를 지원하는 다른 프레임워크에서 가져와 다양한 환경에서 사용할 수 있다.ONNX-RT(ONNX Runtime)ONNX가 모델을 표현하고 교환하는 것을 처리 동안에 ONNX 연산자의 최적화된 구현을 제공하고 계산을 병렬화하여 효율적인 ONNX 모델을 실행 및 추론하는 엔진TVM compilerApache에서 개발한 딥러닝 컴파일러로 모델을 타겟 디바이스에서 최적의 속도와 정확도를 낼 수 있는 코드 변환 작업 도구다양한 프레임워크로 부터 모델을 통합된 형태로 컴파일통합된 모델을 타겟 하드웨어에 최적화된 형태로 실행"
  },
  
  {
    "title": "신경망 (Neural Network)",
    "url": "/posts/neural_network/",
    "categories": "ML",
    "tags": "ML, NearalNetwork",
    "date": "2023-02-27 00:00:00 +0900",
    





    "snippet": "신경망 (Nearal Network)입력 데이터feature map필터_(레이어에 들어오는 값 x 레이어의 가중치 행렬) &gt; 활성화 함수채널 수 = 필터 수CNNConvolution 연산을 통해 위치별로 가지고 있는 패턴을 찾아 특징을 추출이미지 전체 사이즈의 conv 연산을 하는 것이 아니라, 어떤 특징을 잘 추출하기 위한 3x3 등의 사이즈를 가진 필터로 이미지의 작은 부분에 대해 연산을 하고 바라본 부분의 엣지와 같은 특성을 파악  3x3 conv9개의 weightreceptive field가 좁음  5x5 conv25개의 weight  3x3 conv + 3x3 conv18개의 weight5x5 conv와 같은 크기의 receptive field를 봄###  input data  data custom  input layer"
  },
  
  {
    "title": "분야별 주요 모델",
    "url": "/posts/Model/",
    "categories": "ML",
    "tags": "ML, Model",
    "date": "2023-02-27 00:00:00 +0900",
    





    "snippet": "SOTA(State-of-the-art) 모델현재 최고 수준의 결과를 가진 모델  최신 연구 트랜드 확인scikit-learn 머신러닝 기법 참고Pytorch 사전학습 모델 확인지도 학습회귀 (Regression)  선형 회귀 (Linear Regression)  로지스틱 회귀 (Logistic Regression)  Support Vector Regression (SVR)  의사결정 트리 회귀 (Decision Tree Regression)  랜덤 포레스트 회귀 (Random Forest Regression)  그래디언트 부스팅 회귀 (Gradient Boosting Regression)          XGBoost      LightGBM        신경망 (Neural Network)분류 (Classification)  로지스틱 회귀 (Logistic Regression)  Support Vector Machine (SVM)  의사결정 트리 (Decision Tree)  Naive Bayes  k-최근접 이웃 (k-Nearest Neighbors, k-NN)  랜덤 포레스트 (Random Forest)  그래디언트 부스팅 (Gradient Boosting)  신경망 (Neural Network)          CNN (Convolutional Neural Network)      시계열 예측 (Time series forecasting)  AR (Auto Regression)  MA (Moving average)  ARMA (Autoregressive Moving average)  ARIMA (AutoRegressive Intergrated Moving Average)  RNN (Recurrent Neural Network)  LSTM (Long Short-Term Memory)앙상블 학습 (Ensemble Learning)  Voting          Hard Voting      Soft Voting        Bagging (bootstrap aggregation)          랜덤 포레스트 (Random Forest)        Boosting          AdaBoost      Gradient Boosting Machine (GBM)                  Catboost          XGBoost (eXtra Gradient Boost)          LightGBM                      Stacking멀티 모달 (Multi Modal)  시각          이미지      비디오        청각          음성      음악        언어          텍스트      음성 인식        촉각          형태      질감        미각  후각비지도 학습군집화 (Clustering)  계층적 클러스터링 (Hierarchical Clustering)          BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)        분할적 클러스터링 (Partitional Clustering)          K-Means      K-median      K-medoid        밀도 기반 클러스터링 (Density-based Clustering)          Mean-Shift      DBSCAN (Density-Based Spatial Clustering of Applications with Noise)      DBCLASD (Density-Based CLASsification and Discovery)      OPTICS (Ordering Points To Identify the Clustering Structure)        그리드 기반 클러스터링 (Grid-based Clustering)          OptiGrid        Gaussian Mixture Model (GMM)  Fuzzy C-Means (FCM)    차원 축소 (Dimensionality Reduction)차원의 저주https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41#fbea      PCA (Principal Component Analysis)다차원 데이터를 저차원 공간으로 변환하는 통계적 기술입니다. 이 기술은 데이터의 차원을 줄이고 중요한 정보를 보존하는 데 사용됩니다. 주로 데이터 압축, 시각화, 차원 감소, 노이즈 제거 등 다양한 데이터 분석 및 머신 러닝 작업에서 활용    t-SNE (t-Distributed Stochastic Neighbor Embedding)  MCA (Multiple Correspondence Analysis)이미지 모델이미지 분류(Classification)  LeNet (1998)  AlexNet (2012)  ZFNet (2013)  VGGNet (2014)  GoogLeNet (Inception) (2014)  ResNet (2015)  SqeezeNet (2016)  DenseNet (2016)  MobileNet (2017)  EfficientNet (2019)  ViT (Vision Transformer) (2020)객체 감지(Object Detection)  R-CNN  Fast R-CNN  Faster R-CNN (2015)Fast R-CNN에 RPN(Region Proposal Networks)을 도입  YOLO (You Only Look Once) (2015)이미지를 그리드로 나누고 바운딩 박스와 클래스 확률을 예측하여 실시간으로 객체를 감지  SSD (Single Shot MultiBox Detector) (2016)단일 네트워크에서 다양한 규모와 종횡비로 여러 바운딩 박스 예측을 결합  RetinaNet (2017)객체 감지의 클래스 불균형 문제를 해결하기 위해 Focal Loss를 도입  Mask R-CNN (2017)Faster R-CNN을 기반으로 마스크 예측 분기를 추가  EfficientDet (2019)모델의 깊이, 너비, 해상도 간에 균형을 잡고 아키텍처를 최적화  DETR (Data-efficient Image Transformer) (2020)Transformer 기반의 아키텍처를 도입해 감지와 인식을 통합된 방식으로 처리  Swin Transformer    객체 추적(Object Tracking)  LSTM  DeepSORT포인트 클라우드 모델  VoxelNet  PointNet++  PointPillars언어 모델NLP  RNN (Recurrent Neural Networks)  LSTM (Long Short-Term Memory)  Word2Vec  GRU (Gated Recurrent Unit)  Doc2Vec  Seq2Seq (Sequence-to-Sequence)  FastText  Transformer  BERT (Bidirectional Encoder Representations from Transformers)  GPT (Generative Pre-trained Transformer)  XLNet  T5 (Text-to-Text Transfer Transformer)  RoBERTa"
  },
  
  {
    "title": "머신러닝 벤치마크(Benchmark)",
    "url": "/posts/benchmark/",
    "categories": "ML",
    "tags": "ML, Benchmark",
    "date": "2023-02-22 00:00:00 +0900",
    





    "snippet": "벤치마크(Benchmark)다양한 분야에서 사용되고 있는 ‘벤치마크’는 일반적으로 무언가를 측정, 평가, 비교할 수 있는 표준을 의미한다.‘벤치마크’는 머신러닝에서도 자주 등장하는데,알고리즘이나 모델의 성능을 평가하고 비교하는 데 일반적으로 사용되는 표준화된 데이터 세트나 평가 지표를 말할 때 사용한다.그리고 이렇게 모범 사례로 확립된 벤치마크와 머신러닝 모델 또는 알고리즘 기술을 비교하는 행위를 ‘벤치마킹’한다고 말한다.벤치마킹의 목적  객관적인 성능 평가여러 사람들이 같은 목적에 대해 설계한 다양한 머신러닝 모델의 성능을 객관적으로 측정하고 비교할 수 있다.  모델 선택사용할 머신러닝 모델을 선정할 때 특정 상황에 적합한 모델이 어떤 것인지 판단하는데 도움이 될 수 있다.  진행 상황 추적빠르게 지속적으로 개발되는 알고리즘과 기술이 과거에서 어떻게 진행되고 있는지 상황을 추적할 수 있다.벤치마크 데이터셋Kaggle이나 Github 등에서 원하는 데이터셋을 검색하여 사용할 수 있다.이미지 분류      ImageNet매년 열리는 ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 대회에서 사용되는 데이터셋이다.이미지 분류를 위한 데이터셋으로 유명하고 널리 사용됨수천 개의 클래스에 수백만 개의 라벨링된 이미지가 들어있음        CIFAR-1010개 클래스에 각각 6000개씩 총 60000개의 32x32 컬러 이미지가 들어있음        CIFAR-100100개 클래스에 각각 600개의 이미지가 들어있음        STL-10        MNIST숫자 인식 작업에 사용되는 데이터셋으로 머신러닝에 입문하는 사람들이 많이 사용손으로 쓴 0~9 숫자의 28x28 흑백 이미지가 들어있음        Fashion-MNIST의류, 액세서리 등 패션 아이템 데이터셋10개 클래스로 28x28 흑백 이미지가 들어있음        SVHN (Street View House Numbers)        Caltech-101        Oxford Flowers        Oxford Pets        Stanford Dogs              데이터셋      해상도      클래스 수      학습 데이터 수      테스트 데이터 수      용량                  ImageNet      224 x 224 (color),256 x 256 (color),등      1,000      1,200,000 이상      50,000 이상      150 GB 이상              CIFAR-10      32 x 32 (color)      10      50,000 (클래스당 5000)      10,000 (클래스당 5000)      약 163 MB              CIFAR-100      32 x 32 (color)      100      50,000 (클래스당 500)      10,000 (클래스당 500)      약 161 MB              STL-10      96 x 96 (color)      10      5,000 (클래스당 500) labeled,100,000 unlabeled      8,000 (클래스당 800)                     MNIST      28 x 28 (gray)      10      60,000      10,000                     Fashion-MNIST      28 x 28 (gray)      10      60,000      10,000                     SVHN (Street View House Numbers)      32 x 32 (color)      10      73,257(+ 531,131 less difficult)      26,032                     Caltech-101      약 300 x 200      101      약 6,000      약 3,000      약 137.4 MB (.zip)              Oxford Flowers             102      1,664      6,520                     Oxford Pets             37      약 3,680      약 3,680                     Stanford Dogs             120      약 12,000      약 8,000             Object Detection      PASCAL VOC        COCO (Common Objects in Context)객체 감지 및 분할을 위한 데이터셋        KITTI  자연어 처리(NLP)      IMDb        Named Entity Recognition (NER)        SQuAD (Stanford Question Answering Dataset)  "
  },
  
  {
    "title": "머신러닝에 사용되는 프로세서",
    "url": "/posts/processor/",
    "categories": "ML",
    "tags": "Processor",
    "date": "2023-02-16 00:00:00 +0900",
    





    "snippet": "프로세서CPU(Central Processing Unit)컴퓨터 시스템의 중앙 처리 장치로 두뇌의 역할을 한다.다양한 환경에서 작업을 빠르게 수행하기 위해 복잡한 ALU(산술논리장치)의 구조를 가지고 있는 대신에 하나의 명령어로 처리할 수 있는 기능이 많고 각종 제어 처리를 담당한다.멀티태스킹을 위해 나눈 작업들에 우선순위를 지정하고 전환하며 가상 메모리를 관리하는 등 컴퓨터를 지휘하는 역할을 수행한다.컴퓨터 프로그램은 대부분 복잡한 순서를 가진 알고리즘으로 동작하기 때문에 CPU를 사용하는 것이 적절하다.      (직렬처리에 최적화된 몇 개의 코어로 구성)  장점          다양한 프로그래밍 작업에서 사용 가능      전력 소비가 상대적으로 적음        단점          병렬처리 작업이 제한적임      GPU(Graphics Processing Unit)그래픽 처리 장치로 특화된 연산을 빠른 속도로 처리하기 위해 단순한 ALU를 여러 개 갖고 있는 구조로 되어있다.영상 작업은 하나의 픽셀마다 연산을 하기 때문에 처음에는 CPU에서 데이터를 보내 빠르게 그래픽 처리를 하기 위한 목적으로 만들어졌지만,반복적이고 비슷한 대량의 연산을 병렬적으로 나누어 수행하는 방법 덕분에 결과적으로 CPU 보다 훨씬 빠른 연산 속도를 보여주면서 딥러닝 모델 훈련 및 실행에 사용되기 시작해 좋은 성능을 내고 있다.      (병렬처리용으로 설계된 수 천 개의 효율적인 코어로 구성)코어 하나의 연산 능력이 높아 고가인 CPU 코어를 GPU 처럼 수천개씩 붙여 연산하는 것은 비용이나 전력, 기술적으로 비효율적이기 때문에 GPU를 사용하여 병렬 연산을 한다.하지만 이러한 GPU도 결국 CPU의 제어를 받으며 계산된 AI 결과도 CPU를 통해 제어한다.  장점          대규모 데이터셋과 복잡한 모델을 효율적으로 처리하여 시간을 크게 단축시킬 수 있음        단점          전력 소비가 큼      CPU vs GPU수천 개의 코어를 가지고 있어 병렬적인 작업(Paraller Task)에서 강점을 발휘하는 GPU의 사용이 무조건 CPU보다 좋은 성능을 내는 것은 아니다.      작업 처리 방식CPU는 4~10개 내외로 적은 수의 코어만을 가지고 있지만 코어 자체는 GPU보다 고성능이기 때문에 순차적인 작업(Sequential Task)에서 강점을 가지고 있다.따라서 병렬도가 낮고 연산식과 데이터가 함께 바뀌는 경우에는 CPU가 더 강력한 컴퓨팅 파워를 발휘한다.    CPU는 연산식과 데이터가 랜덤하게 변하는 환경을 가정하여 설계했지만,GPU는 제어부가 상대적으로 부실하기 때문에 이런 환경에서는 ALU가 작업을 하지 않고 노는 시간이 생긴다.(예를 들어 if문을 사용하면 코드가 두 개로 갈라지는데, 이를 CPU에서 처리하지 않고 GPU에서 돌아갈 코드로 넣으면나뉘어진 데이터의 양이 GPU의 가용 자원을 전부 활용할 정도가 아닐 경우, 앞쪽 코드가 다 처리된 후에 반대편 코드의 계산을 재개하기 때문에 반대편 데이터를 대기시켜놓으면서 자원을 활용하지 못해 성능이 떨어질 수 있다.)        데이터 통신에서의 병목CPU와 GPU 간에는 서로 PCI-E를 통해서 통신하는데 통신 대역폭이 VGA의 로컬 메모리 대역폭보다 부족하고,물리적으로 떨어져 있다보니 레이턴시가 생겨 데이터 전송에서 병목현상이 발생해 성능이 저하되는 경우가 있다.                            PCI-E(Peripheral Component Interconnect Express)          컴퓨터 시스템에서 하드웨어 컴포넌트 간에 데이터 통신을 할 수 있게 해주는 컴퓨터 버스 표준                      작은 데이터를 하나하나 던져주면 GPU의 처리속도가 빨라도 데이터를 보내고 받는 시간에서 많이 잡아먹기 때문에 성능이 나오지 않는다.(데이터셋이 작은 경우에는 오히려 CPU만으로 연산하는 것이 GPU를 사용했을 때 보다 빠르거나 별 차이가 없을 때가 있었다.)                  일반적인 CPU 프로그래밍                  데이터를 가져옴          로직에 넣음          결과를 사용                    GPU 연산 프로그래밍                  데이터를 가져옴          GPU에 전송할 데이터를 준비          GPU로 데이터 전송          결과를 기다림          GPU에서 결과 데이터를 수신          수신한 데이터에서 사용할 결과를 추출                      이러한 과정 때문에 CPU 입장에서는 한번 데이터를 주고 받는데 상당한 시간이 소요되고 이를 개선하기 위해 한번에 데이터를 묶어서 보내는 ‘배치 학습 방법’이 나온 것 같다.  (참고) GPU 연산을 위한 요구사항  프로그램 가능한 셰이더그래픽 카드가 기본 지원하지 않는 셰이더를 그릴 수 있어 렌즈 효과, 변위 매핑, 필드 깊이 등의 추가적인 표현이 가능해지고 이를 이용하여 연산  데이터 자료형 추가일반 그래픽 응용처럼 모든 계산이 행렬식으로 처리되지는 않기 때문에 필요  소프트웨어 적으로 변환시키는 라이브러리CUDA, OpenCL, 등MPU(Micro Processor Unit)연산만을 목적으로 만들어진 CPU역할을 하는 장치로 ALU와 연산 입력 값을 처리하기 위한 시프트 레지스터로 이루어져 있다.(RAM, ROM, I/O 등의 장치를 추가해주어야 작동 가능)특정 딥러닝 작업에 특화된 하드웨어 가속기로 사용  장점          딥러닝 작업을 최적화하기 위해 설계되어 빠른 성능을 제공      GPU보다 낮은 전력을 소비        단점          딥러닝 이외의 다른 종류 작업에는 제한적      성능 최적화 지원이 특정 딥러닝 프레임워크에 한정            MCU(Micro Controller Unit)마이크로프로세서(초소형 연산 처리 장치)와 입출력 모듈을 하나의 칩으로 만든 장치연산뿐만 아니라 주변의 장치를 제어한다.(CPU 코어, 메모리, 프로그램 가능한 입출력으로 구성되어 있어 정해진 기능을 수행하도록 프로그래밍하고 메모리에 써넣음)      TPU(Tensor Processing Unit)구글에서 머신러닝 워크로드를 빠르게 처리하기 위해 설계한 ASIC(Application Specific Integrated Circuit)Tensorflow나 TFLite를 프레임워크로 사용할 때만 쓸 수 있다.        Edge TPU저전력으로 최적화하여 Edge용으로 공개한 Edge TPU도 존재하며, 스마트폰 같은 소형 기기에서 볼 수 있다.Edge TPU 성능 비교DPU(Data Processing Unit)데이터센터에서 주로 네트워크, 보안, 저장소, 가상화 및 기타 데이터 중심 작업을 수행하는 데 사용되는 데이터 중심 가속 컴퓨팅을 위한 장치이다.고성능 네트워크 인터페이스로 데이터를 파싱(parsing) 및 처리하고, 데이터를 GPU 및 CPU로 효율적으로 전송한다.      "
  },
  
  {
    "title": "Pytorch 익숙해지기",
    "url": "/posts/pytorch_tutorial/",
    "categories": "ML",
    "tags": "Pytorch",
    "date": "2023-02-10 00:00:00 +0900",
    





    "snippet": "PytorchPytorch DL 튜토리얼  참고          파이토치 공식 튜토리얼      파이토치 한국 튜토리얼      도메인 라이브러리  TorchText  TorchVision  TorchAudio파이토치에서는 도메인에 특화된 라이브러리를 구분해놓고 이를 import해서 각각의 모듈과 데이터셋을 사용할 수 있도록 기능을 제공해준다.예를 들어 TorchVision에서 datasets 모듈을 통해 CIFAR, COCO 등의 다양한 비전 데이터셋을 불러올 수 있다.import torchfrom torch import nn공개 데이터 다운로드 받기TorchVision의 데이터셋 목록from torchvision import datasetsfrom torchvision.transforms import ToTensor# 학습 데이터 다운로드training_data = datasets.FashionMNIST(    root=\"data\",    train=True,  # train    download=True,    transform=ToTensor(),)# 테스트 데이터 다운로드test_data = datasets.FashionMNIST(    root=\"data\",    train=False,  # test    download=True,    transform=ToTensor(),)데이터셋을 DataLoader 객체로 만들기from torch.utils.data import DataLoaderbatch_size = 64# 데이터로더 생성train_dataloader = DataLoader(training_data, batch_size=batch_size)test_dataloader = DataLoader(test_data, batch_size=batch_size)for X, y in test_dataloader:    print(f\"Shape of X [N, C, H, W]: {X.shape}\")    print(f\"Shape of y: {y.shape} {y.dtype}\")    break"
  },
  
  {
    "title": "AI 카테고리 살펴보기",
    "url": "/posts/AI_Research/",
    "categories": "ML",
    "tags": "AI, ML",
    "date": "2023-02-07 00:00:00 +0900",
    





    "snippet": "AI 직업크게 보았을 때 AI 관련 직업은 ‘데이터 분석가’, ‘데이터 엔지니어’, ‘데이터 사이언티스트’, ‘AI Reseaucher(모델러)’이다.  데이터 분석가데이터를 비즈니스에 활용할 수 있도록 분석(Tableau, Power BI, Python, R, SQL, 시각화 도구)  데이터 엔지니어데이터를 수집하고 저장, 처리할 수 있는 아키텍처(데이터 파이프라인, DB, ETL)를 관리(Hadoop, Spark, Kafka, Java, Python, SQL)  데이터 사이언티스트데이터를 분석 및 시각화하면서 의미있는 데이터로 정제하고 예측 모델을 구현(Python, R, SQL, Tensorflow, PyTorch)  AI Researcher모델 고도화, 경량화, 최신 기법 적용(Python, C, C++, Tensorflow, PyTorch)인공지능 소개  인공지능(AI, Artificial Intelligence)인간의 학습 능력, 추론(Inference) 능력, 지각 능력을 가진 컴퓨터 시스템을 만드는 기술로 인간의 사고를 모방하는 모든 것  머신러닝(ML, Machine Learning)인공지능의 한 분야로 사람이 정한 특징 추출 방법과 모델을 통해 데이터를 기반으로 스스로 규칙을 학습해서 추론할 수 있도록 하는 기술  딥러닝(DL, Deep Learning)머신러닝 알고리즘 중 인공 신경망을 기반으로 한 방법들을 통칭하는 것으로 빅데이터 학습에 적합하다.      인공지능의 단계  약인공지능특정 분야에 유용한 도구로만 활용 가능한 인공지능  강인공지능인간을 완벽하게 모방하여 다양한 분야에서 활용 가능한 인공지능  초인공지능강인공지능에서 자아를 가진 인공지능학습 방법  지도 학습레이블된 데이터를 기반으로 모델을 훈련  준지도 학습레이블이 지정된 데이터와 레이블이 지정되지 않은 데이터를 함께 사용하여 모델을 훈련  비지도 학습레이블이 지정되지 않은 데이터를 기반으로 모델을 훈련  강화 학습에이전트가 환경과 상호작용하여 시행착오를 겪으면서 받는 보상 신호를 통해 학습프레임워크  Scikit-Learn파이썬 머신러닝 라이브러리  Tensorflow구글에서 개발한 오픈 소스 딥러닝 라이브러리Keras API와 함께 사용(tf.Tensor 데이터 유형을 사용하여 다차원 배열로 표현)  PytorchFacebook의 AI Research lab(FAIR)에서 개발한 오픈 소스 딥러닝 프레임워크(torch.Tensor 데이터 유형을 사용하여 다차원 배열로 표현)  Caffe (Convolutional Architecture for Fast Feature Embedding)이미지 관련 작업에 많이 사용되는 프레임워크  Theano행렬같은 수학 계산을 위한 라이브러리학습 모델  회귀  분류  이미지 처리  자연어 처리(NLP)  음성 모델  거대언어 모델(LLM)  생성형 모델학습 데이터  정형 데이터 (Structured Data)미리 정해놓은 형식에 따라 고정된 필드에 저장된 데이터  비정형 데이터정의된 구조가 없는 동영상, 오디오, 사진, 문서, 등  반정형 데이터데이터의 구조 정보가 데이터와 함께 제공되어 형식이 변경될 수 있는 데이터(XML, HTML, JSON, …)  시계열 데이터시간 간격으로 수집된 데이터  이미지 데이터그리드에 배열된 픽셀 형태의 정보  텍스트 데이터텍스트 정보  오디오 데이터음성 정보이미지 처리 태스크  이미지 분류(Image Classification)이미지가 무엇인지 분류  이미지 분류 + Localiztion이미지 내에 어떤 객체가 있는지 분류하고 어디에 위치하는지 파악  이미지 분할(Image Segmentation)          Semantic Segmentation이미지에서 개체에 대한 클래스만 식별 (label에서 개체간에 구분X)      Instance Segmentation이미지에서 여러 개체들을 식별하고 각 개체의 픽셀을 분할 (클래스 식별X)      Panoptic Segmentation이미지에서 픽셀의 클래스를 구분하고 인스턴스 분할을 동시에 수행            객체 탐지(Object Detection)객체의 위치를 식별하고 분류  객체 추적(Object Tracking)객체를 식별하고 추적  얼굴 인식(Face Recognition)얼굴 특징을 기반으로 개인을 식별  얼굴 표정 인식(Facial Expression Recognition)얼굴 표정을 감지하고 감정을 분석  나이 성별 추정(Age and Gender Estimation)개인의 나이와 성별을 추정  이미지 캡션(Image Captioning)이미지에 대한 자연어 설명 또는 캡션 생성  초해상도(Image Super-Resolution)의료 영상이나 위성 영상 등에서 이미지의 품질과 해상도를 향상시키는 것  이미지 노이즈 제거이미지에서 노이즈와 아티팩트를 제거  Image Inpainting이미지에서 누락되거나 손상된 부분을 채움  Style Transfer한 이미지의 예술적 스타일을 다른 이미지의 콘텐츠에 적용  이미지 등록(Image Registration)이미지를 정렬하고 오버레이하여 비교하거나 결합  Panorama Stitching여러 이미지를 하나의 광각 이미지나 파노라마 이미지로 결합  필기 인식필기한 문자를 기계가 읽을 수 있는 텍스트로 변환  문서 레이아웃 분석문서를 텍스트, 이미지, 표 등의 영역으로 분할하고 구조화된 정보를 추출OCR(광학 문자 인식)에 필요  컨텐츠 기반 이미지 검색(Content-Based Image Retrieval, CBIR)시각적 컨테츠를 기반으로 DB에서 이미지를 검색  이상 감지(Anomaly Detection)불규칙하거나 예상치 못한 패턴을 식별  깊이 추정(Depth Estimation)이미지의 각 픽셀에 대한 깊이나 거리를 예측자연어 처리 태스크  감정 분석 (Sentiment Analysis)텍스트 데이터에서 감정을 분석  텍스트 분류다양한 유형의 게시물에서 스팸 필터링, 언어 감지, 주제 분류  텍스트 생성시나리오, 소설, 기사, 등의 텍스트를 생성  번역 (Translation)언어간에 정보를 번역하고 이해  자동 요약긴 텍스트 문서를 자동으로 요약  텍스트 마이닝대량의 텍스트 데이터에서 유용한 정보를 추출  대화형 AI챗봇이나 가상 비서를 만들어 사용자와 대화  개체명 인식 (Named Entity Recognition, NER)텍스트에서 특정 개체명(사람, 장소, 날짜, 등)을 식별하고 추출  검색검색 엔진, 문서 검색 및 추천 시스템 개발"
  },
  
  {
    "title": "SK-AM62 evm 사용",
    "url": "/posts/sk_am62/",
    "categories": "Project",
    "tags": "TI, SK-AM62",
    "date": "2022-09-20 00:00:00 +0900",
    





    "snippet": "우분투 설치우분투 이미지 다운로드우분투 이미지 다운로드우분투 버전은 각자의 프로젝트에 맞게 recommend 버전이 있다면 해당 버전을 선택하고, 없다면 환경을 고려하여 설치하면 된다.(ex. 버전에 따라 기본으로 설치되어 있는 파이썬 버전이 다르거나 드라이버 오류가 다르게 발생, 등)우분투 이미지를 다운받을 때 버전 이외에도 다음과 같은 고려사항이 있다.  Ubuntu최신 기능과 애플리케이션을 빠르게 경험할 수 있지만 지원 기간이 짧다.(일반적으로 약 6개월의 릴리즈 주기로 새로운 버전 출시)      Ubuntu LTS(Long Term Support)안정적인 운영을 중요시 하여 새로운 기능보다는 안정성과 보안 패치, 버그 수정을 중심으로 업데이트를 제공한다. 또한 5년 내외의 긴 지원 기간을 가지기 때문에 기업이나 서버에 사용하기 적합하다.(일반적으로 약 2년의 릴리즈 주기로 새로운 버전 출시)    Ubuntu DeskTopGUI까지 제공해주기 때문에  Ubuntu Server부팅용 usbRufus 다운로드Rufus를 실행해 다운로드 받은 우분투 이미지를 선택하고 시작을 눌러 부팅용 usb를 만들어 준다.우분투 설치윈도우가 설치되어 있는 PC에 우분투를 추가로 설치해 듀얼 부팅으로 사용하고 싶을 때,      하나의 디스크에 설치하는 경우윈도우의 볼륨(C:)을 축소하고 free space에 우분투를 설치하는 경우(free space에 새 볼륨을 만들면 우분투를 설치할 때 마운트할 파티션으로 들어가기 때문에 할당되지 않은 남은 공간을 그대로 두고 설치를 시작해야 함)에는 우분투 부트로더(grub)를 윈도우의 부트 매니저와        두 개의 디스크에 각각 설치하는 경우SSD나 하드디스크를 추가하여 새로운 디스크에 우분투를 설치할 경우 부트로더를 우분투를 설치하는 하드디스크에 설치해야 한다.  ‘Win + R’을 누르고 ‘diskmgmt.msc’를 입력하면 디스크 관리 창이 나온다.우분투 부팅 실패부팅 시 /dev/nvme0n1p0: clean, xxxxxx/xxxxxxx files, xxxxxxx/xxxxxxxx blocks 라는 메시지에서 화면이 멈추고 더 이상 진행이 되지 않을 때우분투를 다른 버전으로 다시 설치해야 하나 했지만 구글에 ‘우분투 clean files blocks’라고 검색해보니 오류를 해결한 케이스들을 찾아볼 수 있었다.해결 방법은  멈춘 화면에서 장시간 기다려보기  부트로더를 올바른 위치로 지정하여 설치했는지 확인  그래픽 드라이버 재설치정도로 찾아볼 수 있었다.이번 경우에는 장시간 기다려봐도 변화가 없어 아래와 같이 그래픽 드라이버를 재설치하는 방법으로 해결했다.  Advanced options for Ubuntu 선택  Ubuntu, with Linux x.x.x-xx-generic (recovery mode) 선택  (recovery mode가 여러개 있었지만 가장 위에 있는 것으로 선택해서 진행했다.)  Recovery Menu에서 root 의 Drop to root shell prompt 항목으로 이동 후 엔터  (하단에 검은색 창에 ‘Press Enter for maintenance’ 메시지가 출력되면 여기서 엔터를 눌러주어야 커맨드 입력이 가능해진다.)  sudo apt update  sudo apt upgrade  ubuntu-drivers devices  (설치 가능한 드라이버 목록 확인)  sudo apt install nvidia-driver-535  (NVIDIA 홈페이지에서 3060Ti 그래픽카드에 대해 지원중이고, ‘distro non-free recommended’ 라고 적혀있는 535버전으로 선택했다.)  sudo reboot만약 그래픽 드라이버를 재설치 해도 계속 부팅이 되지 않는다면 설치 가능 목록 중 다른 드라이버로 재설치해보는 것이 좋을 것 같다.SK-AM62 EVMAM625를 사용하여 제작된 am62x starter kit(AM62x와 AM62Ax 구분에 유의)Download page  Image writing utility (SD card)balenaEtcher  SD card imagePROCESSOR-SDK-AM62XQuick start참고 : AM62x Start Guide      통신PC와 UART 연결을 하면 4개의 포트가 잡히고 TeraTerm을 통해 첫번째 포트로 연결할 수 있다.        부팅보드에 전원을 넣어주면 부팅이 시작되고, 중간에 ‘Hit any key to stop autoboot:   3’ 이라는 메시지가 나오는데 이 때 3초 안에 아무키나 누르면 U-Boot prompt ‘=&gt;‘가 나온다. (부트로더로 U-Boot 사용)여기서 사용할 수 있는 몇 가지 명령어들이 있는데 그 중 ‘boot‘를 입력하면 부팅이 진행된다.        로그인부팅이 완료되면 ‘am62xx-evm login:‘이라고 나오는데 root를 입력해주면 로그인이 된다. (Yocto 이미지에는 gcc랑 python만 기본적으로 설치되어 있음)  카메라 스트리밍SK-AM62 evm으로 카메라 스트리밍을 할 때 SD카드에 플래시한 Yocto 이미지에는 ov5640의 CSI-2 센서만 드라이버 파일이 들어있었다.RPI 카메라 v2.1로 연결해보았으나 인식이 되지 않아서 로지텍 c270 카메라를 구입해서 진행했다.()(USB 카메라는 video, CSI-2 카메라는 media로 잡힌다)  (데비안 환경에서 패키지가 설치되어 있지 않은 경우)    sudo apt install v4l-utils        이미지 센서 검색    v4l2-ctl --list-devices        카메라에서 지원하는 포맷 확인    v4l2-ctl --list-formats -d /dev/video0        로지텍 c270 스트리밍    gst-launch-1.0 v4l2src device=/dev/video0 ! videoconvert! videoscale ! video/x-raw, width=800, height=600 ! autovideosink          Host PC  Ubuntu 18.04 LTS DeskTop  Python 3.6.9  SDK - 08_03_00_19(ti-processor-sdk-linux-am62xx-evm-08.03.00.19-Linux-x86-Install.bin)  EdgeAI TIDL Tools - 08_03_00_19edgeai-tidl-tools 깃허브사전 설치sudo apt updatesudo apt upgradesudo apt install net-toolssudo apt install vimsudo apt install openssh-server(포트포워딩으로 외부 접속도 가능)sudo apt install gitsudo apt install python3-pipPC Setupgit clone https://github.com/TexasInstruments/edgeai-tidl-tools.gitexport DEVICE=am62cd edgeai-tidl-toolssource ./setup.sh./models와 ./model-artifacts가 생성되면 evm에 복사오류 발생 시 패키지가 정상적으로 설치되었는지 확인pip3 install -r requirements_pc.txtonnx==1.9.0 설치 오류 시참고 : onnx==1.9.0  cmake 설치    sudo apt-get install cmake        우분투처럼 아나콘다 환경이 아닌 경우 설치    sudo apt-get install protobuf-compiler libprotoc-dev        pip3 install onnx==1.9.0          주피터 노트북 example참고 : Jupyter Notebooksudo apt-get install jupytercd examples/jupyter_notebookssource ./launch_notebook.sh  최초 실행 이후에는 다운로드 스킵    source ./launch_notebook.sh --skip_setup --skip_models_download        Host PC의 IP 확인    ifconfig      http://192.168.x.xxx:8888/tree 접속메시지에 출력된 로그인 토큰(http://0.0.0.0:8888/?token=xxxxxxxxxxxxxxxxx 처럼 중 x부분)를 복사해서 입력하면 주피터 노트북 페이지에 접속됨혹은 http://0.0.0.0:8888/?token=xxxxxxxxxxxxxxxxx 링크를 열어도 접속 가능SDK 설치 후 emulation  SK-AM62 접속    minicom -w      "
  },
  
  {
    "title": "TI people counting CLI 함수 정리",
    "url": "/posts/ti_radar_cli/",
    "categories": "Radar",
    "tags": "Radar, Configuration, Command, CLI",
    "date": "2022-07-15 00:00:00 +0900",
    





    "snippet": "People Counting CLIoverhead_3d_people_count_6843_mss/mss/mss_main.c      CLI task 시작main() -&gt; Pcount3DDemo_initTask() -&gt; Pcount3DDemo_CLIInit() -&gt; CLI_open() -&gt; CLI_MMWaveExtensionInit() -&gt; CLI_task()        CLI command 실행Pcount3DDemo_CLISensorStop() … -&gt; Pcount3DDemo_CLISensorStart() -&gt; CLI_getMMWaveExtensionConfig() -&gt; CLI_getMMWaveExtensionOpenConfig -&gt; …  CLI를 위해 필요한 파일      pcount3D_cli.cpeople counting 용 command table entry 및 함수        cli_mmwave.cpeople counting 프로젝트 이외에 다른 프로젝트에서도 사용되는 Extension command table entry 및 함수(해당 파일이 include 되진 않고 extern으로 정의된 함수들만 불러들여짐)    (해당 파일의 함수를 추가로 사용하기 위해서cli_open()에서 CLI_MMWaveExtensionInit(), CLI_getMMWaveExtensionConfig()을cli_open에서 CLI_getMMWaveExtensionOpenConfig()을cli_task()에서 CLI_MMWaveExtensionHandler()을 실행한다.)        cli.c / cli.h / cli_internal.hcli task 및 structure 정의        tracker_utils.c / tracker_utils.htracking 용 함수        mmwdemo_adcconfig.c / mmwdemo_adcconfig.hadc Buffer와 관련된 함수 정의        pcount3D_mss.hstructure 정의        pcount3D_config.hstructure 정의        mmwave.h / mmwavelink.hstructure 정의  CLI Initti/mmwave_sdk_03_05_00_04/packages/ti/utils/cli/cli.htypedef struct CLI_Cfg_t{    // CLI Prompt string (if any to be displayed)    char*               cliPrompt;    // Optional banner string if any to be displayed on startup of the CLI    char*               cliBanner;    // UART Command Handle used by the CLI    UART_Handle         cliUartHandle;    /**     * The CLI has an mmWave extension which can be enabled by this field.     * The extension supports the well define mmWave link CLI command(s)     * In order to use the extension the application should have initialized and setup the mmWave.     */    uint8_t             enableMMWaveExtension;    // The SOC driver handle is used to acquire device part number    SOC_Handle          socHandle;    /**     * The mmWave control handle which needs to be specified if     * the mmWave extensions are being used. The CLI Utility works only     * in the FULL configuration mode. If the handle is opened in     * MINIMAL configuration mode the CLI mmWave extension will fail     */    MMWave_Handle       mmWaveHandle;    // Task Priority: The CLI executes in the context of a task which executes with this priority    uint8_t             taskPriority;    // Flag which determines if the CLI Write should use the UART in polled or blocking mode.    bool                usePolledMode;    // Flag which determines if the CLI should override the platform string reported in @ref CLI_MMWaveVersion.    bool                overridePlatform;    // Optional platform string to be used in @ref CLI_MMWaveVersion    char*               overridePlatformString;    // This is the table which specifies the supported CLI commands    CLI_CmdTableEntry   tableEntry[CLI_MAX_CMD];}CLI_Cfg;overhead_3d_people_count_6843_mss/mss/pcount3D_cli.cvoid Pcount3DDemo_CLIInit (uint8_t taskPriority){    CLI_Cfg     cliCfg;    char        demoBanner[110];    uint32_t    cnt;    /* Create Demo Banner to be printed out by CLI */    sprintf(&amp;demoBanner[0],                     \"***********************************\\n\" \\                    \"IWR68xx Indoor people counting demo\"  \\                    \"***********************************\\n\"            );    /* Initialize the CLI configuration: */    memset ((void *)&amp;cliCfg, 0, sizeof(CLI_Cfg));    /* Populate the CLI configuration: */    cliCfg.cliPrompt                    = \"mmwDemo:/&gt;\";    cliCfg.cliBanner                    = demoBanner;    cliCfg.cliUartHandle                = gMmwMssMCB.commandUartHandle;    cliCfg.taskPriority                 = taskPriority;    cliCfg.socHandle                    = gMmwMssMCB.socHandle;    cliCfg.mmWaveHandle                 = gMmwMssMCB.ctrlHandle;    cliCfg.enableMMWaveExtension        = 1U;    cliCfg.usePolledMode                = true;    cliCfg.overridePlatform             = false;    cliCfg.overridePlatformString       = NULL;            cnt=0;    cliCfg.tableEntry[cnt].cmd            = \"sensorStart\";    cliCfg.tableEntry[cnt].helpString     = \"[doReconfig(optional, default:enabled)]\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLISensorStart;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"sensorStop\";    cliCfg.tableEntry[cnt].helpString     = \"No arguments\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLISensorStop;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"dynamicRACfarCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;leftSkipSize&gt; &lt;rightSkipSize&gt; &lt;leftSkipSizeAzimuth&gt; &lt;rightSkipSizeAngle&gt; &lt;searchWinSizeRange&gt; &lt;searchWinSizeAngle&gt; &lt;guardSizeRange&gt; &lt;guardSizeAngle&gt; &lt;threRange&gt; &lt;threAngle&gt; &lt;threSidelob&gt; &lt;enSecondPass&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIDynRACfarCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"staticRACfarCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;leftSkipSize&gt; &lt;rightSkipSize&gt; &lt;leftSkipSizeAzimuth&gt; &lt;rightSkipSizeAngle&gt; &lt;searchWinSizeRange&gt; &lt;searchWinSizeAngle&gt; &lt;guardSizeRange&gt; &lt;guardSizeAngle&gt; &lt;threRange&gt; &lt;threAngle&gt; &lt;threSidelob&gt; &lt;enSecondPass&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIStaticRACfarCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"dynamicRangeAngleCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;searchStep&gt; &lt;mvdr_alpha&gt; &lt;detectionMethod&gt; &lt;dopplerEstMethod&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIDynRngAngleCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"dynamic2DAngleCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;elevSearchStep&gt; &lt;mvdr_alpha&gt; &lt;maxNpeak2Search&gt; &lt;peakExpSamples&gt; &lt;elevOnly&gt; &lt;sideLobThr&gt; &lt;peakExpRelThr&gt; &lt;peakExpSNRThr&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIDynAngleEstCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"dopplerCfarCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;discardLeft&gt; &lt;discardRight&gt; &lt;guardWinSize&gt; &lt;refWinSize&gt; &lt;threshold&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIDopplerCFARCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"staticRangeAngleCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;staticProcEnabled&gt; &lt;staticAzimStepDeciFactor&gt; &lt;staticElevStepDeciFactor&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIStaticRngAngleCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"fineMotionCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;fineMotionProcEnabled&gt; &lt;fineMotionObservationTime&gt; &lt;fineMotionProcCycle&gt; &lt;fineMotionDopplerThrIdx&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIFineMotionCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"fovCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;azimFoV&gt; &lt;elevFoV&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIAntAngleFoV;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"antGeometry0\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;elem0&gt; &lt;elem1&gt; &lt;elem2&gt; &lt;elem3&gt; &lt;elem4&gt; &lt;elem5&gt; &lt;elem6&gt; &lt;elem7&gt; &lt;elem8&gt;  &lt;elem9&gt; &lt;elem10&gt; &lt;elem11&gt; &lt;elem12&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIBoardAntGeometry0;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"antGeometry1\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;elem0&gt; &lt;elem1&gt; &lt;elem2&gt; &lt;elem3&gt; &lt;elem4&gt; &lt;elem5&gt; &lt;elem6&gt; &lt;elem7&gt; &lt;elem8&gt;  &lt;elem9&gt; &lt;elem10&gt; &lt;elem11&gt; &lt;elem12&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIBoardAntGeometry1;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"antPhaseRot\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;elem0&gt; &lt;elem1&gt; &lt;elem2&gt; &lt;elem3&gt; &lt;elem4&gt; &lt;elem5&gt; &lt;elem6&gt; &lt;elem7&gt; &lt;elem8&gt;  &lt;elem9&gt; &lt;elem10&gt; &lt;elem11&gt; &lt;elem12&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIBoardAntPhaseRot;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"adcbufCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;adcOutputFmt&gt; &lt;SampleSwap&gt; &lt;ChanInterleave&gt; &lt;ChirpThreshold&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIADCBufCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"bpmCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;subFrameIdx&gt; &lt;enabled&gt; &lt;chirp0Idx&gt; &lt;chirp1Idx&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIBpmCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"compRangeBiasAndRxChanPhase\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;rangeBias&gt; &lt;Re00&gt; &lt;Im00&gt; &lt;Re01&gt; &lt;Im01&gt; &lt;Re02&gt; &lt;Im02&gt; &lt;Re03&gt; &lt;Im03&gt; &lt;Re10&gt; &lt;Im10&gt; &lt;Re11&gt; &lt;Im11&gt; &lt;Re12&gt; &lt;Im12&gt; &lt;Re13&gt; &lt;Im13&gt;  &lt;Re20&gt; &lt;Im20&gt; &lt;Re21&gt; &lt;Im21&gt; &lt;Re22&gt; &lt;Im22&gt; &lt;Re23&gt; &lt;Im23&gt; \";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLICompRangeBiasAndRxChanPhaseCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"resetDevice\";    cliCfg.tableEntry[cnt].helpString     = \"No arguments\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = Pcount3DDemo_CLIResetDevice;    cnt++;    cliCfg.tableEntry[cnt].cmd            = \"trackingCfg\";    cliCfg.tableEntry[cnt].helpString     = \"&lt;enable&gt; &lt;paramSet&gt; &lt;numPoints&gt; &lt;numTracks&gt; &lt;maxDoppler&gt; &lt;maxDopplerResolution&gt; &lt;framePeriod&gt; [boresightFilteringFlag - Default is enabled]\";    cliCfg.tableEntry[cnt].cmdHandlerFxn  = MmwDemo_CLITrackingCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"staticBoundaryBox\";    cliCfg.tableEntry[cnt].helpString      = \"&lt;X min&gt; &lt;X Max&gt; &lt;Y min&gt; &lt;Y max&gt; &lt;Z min&gt; &lt;Z max&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIStaticBoundaryBoxCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"boundaryBox\";    cliCfg.tableEntry[cnt].helpString      = \"&lt;X min&gt; &lt;X Max&gt; &lt;Y min&gt; &lt;Y max&gt; &lt;Z min&gt; &lt;Z max&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIBoundaryBoxCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"sensorPosition\";    cliCfg.tableEntry[cnt].helpString      = \"&lt;Z - Height&gt; &lt;Azimuth Tilt&gt; &lt;Elevation Tilt&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLISensorPositionCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"gatingParam\";// PC: 4 gating volume, Limits are set to 3m in length, 2m in width, 0 no limit in doppler    cliCfg.tableEntry[cnt].helpString      = \"&lt;gating volume&gt; &lt;length&gt; &lt;width&gt; &lt;doppler&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIGatingParamCfg;    cnt++;        cliCfg.tableEntry[cnt].cmd             = \"stateParam\";// PC: 10 frames to activate, 5 to forget, 10 active to free, 1000 static to free, 5 exit to free, 6000 sleep to free    cliCfg.tableEntry[cnt].helpString      = \"&lt;det2act&gt; &lt;det2free&gt; &lt;act2free&gt; &lt;stat2free&gt; &lt;exit2free&gt; &lt;sleep2free&gt;\";//det2act, det2free, act2free, stat2free, exit2free, sleep2free    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIStateParamCfg;    cnt++;        cliCfg.tableEntry[cnt].cmd             = \"allocationParam\";// PC: 250 SNR, 0.1 minimal velocity, 5 points, 1m in distance, 2m/s in velocity    cliCfg.tableEntry[cnt].helpString      = \"&lt;SNRs&gt; &lt;minimal velocity&gt; &lt;points&gt; &lt;in distance&gt; &lt;in velocity&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIAllocationParamCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"maxAcceleration\";    cliCfg.tableEntry[cnt].helpString      = \"&lt;max X acc.&gt; &lt;max Y acc.&gt; &lt;max Z acc.&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemoCLIMaxAccelerationParamCfg;    cnt++;    cliCfg.tableEntry[cnt].cmd             = \"presenceBoundaryBox\";    cliCfg.tableEntry[cnt].helpString      = \"&lt;X min&gt; &lt;X Max&gt; &lt;Y min&gt; &lt;Y max&gt; &lt;Z min&gt; &lt;Z max&gt;\";    cliCfg.tableEntry[cnt].cmdHandlerFxn   = MmwDemo_CLIPresenceParamCfg;    cnt++;    /* Open the CLI: */    if (CLI_open (&amp;cliCfg) &lt; 0)    {        System_printf (\"Error: Unable to open the CLI\\n\");        return;    }    System_printf (\"Debug: CLI is operational\\n\");    return;}CLI Openti/mmwave_sdk_03_05_00_04/packages/ti/utils/cli/include/cli_internal.htypedef struct CLI_MCB_t{    // Configuration which was used to configure the CLI module    CLI_Cfg         cfg;    // This is the number of CLI commands which have been added to the module    uint32_t        numCLICommands;    // CLI Task Handle:    Task_Handle     cliTaskHandle;}CLI_MCB;/* CLI Global Variables */extern CLI_MCB gCLI;ti/mmwave_sdk_03_05_00_04/packages/ti/utils/cli/src/cli.cint32_t CLI_open (CLI_Cfg* ptrCLICfg){    Task_Params     taskParams;    uint32_t        index;    /* Sanity Check: Validate the arguments */    if (ptrCLICfg == NULL)        return -1;    /* Initialize the CLI MCB: */    memset ((void*)&amp;gCLI, 0, sizeof(CLI_MCB));    /* Copy over the configuration: */    memcpy ((void *)&amp;gCLI.cfg, (void *)ptrCLICfg, sizeof(CLI_Cfg));    /* Cycle through and determine the number of supported CLI commands: */    for (index = 0; index &lt; CLI_MAX_CMD; index++)    {        /* Do we have a valid entry? */        if (gCLI.cfg.tableEntry[index].cmd == NULL)        {            /* NO: This is the last entry */            break;        }        else        {            /* YES: Increment the number of CLI commands */            gCLI.numCLICommands = gCLI.numCLICommands + 1;        }    }    /* Is the mmWave Extension enabled? */    if (gCLI.cfg.enableMMWaveExtension == 1U)    {        /* YES: Initialize the CLI Extension: */        if (CLI_MMWaveExtensionInit (ptrCLICfg) &lt; 0)            return -1;    }    /* Do we have a CLI Prompt specified?  */    if (gCLI.cfg.cliPrompt == NULL)        gCLI.cfg.cliPrompt = \"CLI:/&gt;\";    /* The CLI provides a help command by default:     * - Since we are adding this at the end of the table; a user of this module can also     *   override this to provide its own implementation. */    gCLI.cfg.tableEntry[gCLI.numCLICommands].cmd           = \"help\";    gCLI.cfg.tableEntry[gCLI.numCLICommands].helpString    = NULL;    gCLI.cfg.tableEntry[gCLI.numCLICommands].cmdHandlerFxn = CLI_help;    /* Increment the number of CLI commands: */    gCLI.numCLICommands++;    /* Initialize the task parameters and launch the CLI Task: */    Task_Params_init(&amp;taskParams);    taskParams.priority  = gCLI.cfg.taskPriority;    taskParams.stackSize = 4*1024;    gCLI.cliTaskHandle = Task_create(CLI_task, &amp;taskParams, NULL);    return 0;}CLI Taskti/mmwave_sdk_03_05_00_04/packages/ti/utils/cli/src/cli.cstatic void CLI_task(UArg arg0, UArg arg1){    uint8_t                 cmdString[256];    char*                   tokenizedArgs[CLI_MAX_ARGS];    char*                   ptrCLICommand;    char                    delimitter[] = \" \\r\\n\";    uint32_t                argIndex;    CLI_CmdTableEntry*      ptrCLICommandEntry;    int32_t                 cliStatus;    uint32_t                index;    /* Do we have a banner to be displayed? */    if (gCLI.cfg.cliBanner != NULL)    {        /* YES: Display the banner */        CLI_write (gCLI.cfg.cliBanner);    }    /* Loop around forever: */    while (1)    {        /* Demo Prompt: */        CLI_write (gCLI.cfg.cliPrompt);        /* Reset the command string: */        memset ((void *)&amp;cmdString[0], 0, sizeof(cmdString));        /* Read the command message from the UART: */        UART_read (gCLI.cfg.cliUartHandle, &amp;cmdString[0], (sizeof(cmdString) - 1));        /* Reset all the tokenized arguments: */        memset ((void *)&amp;tokenizedArgs, 0, sizeof(tokenizedArgs));        argIndex      = 0;        ptrCLICommand = (char*)&amp;cmdString[0];        /* comment lines found - ignore the whole line*/        if (cmdString[0]=='%') {            CLI_write (\"Skipped\\n\");            continue;        }        /* Set the CLI status: */        cliStatus = -1;        /* The command has been entered we now tokenize the command message */        while (1)        {            /* Tokenize the arguments: */            tokenizedArgs[argIndex] = strtok(ptrCLICommand, delimitter);            if (tokenizedArgs[argIndex] == NULL)                break;            /* Increment the argument index: */            argIndex++;            if (argIndex &gt;= CLI_MAX_ARGS)                break;            /* Reset the command string */            ptrCLICommand = NULL;        }        /* Were we able to tokenize the CLI command? */        if (argIndex == 0)            continue;        /* Cycle through all the registered CLI commands: */        for (index = 0; index &lt; gCLI.numCLICommands; index++)        {            ptrCLICommandEntry = &amp;gCLI.cfg.tableEntry[index];            /* Do we have a match? */            if (strcmp(ptrCLICommandEntry-&gt;cmd, tokenizedArgs[0]) == 0)            {                /* YES: Pass this to the CLI registered function */                cliStatus = ptrCLICommandEntry-&gt;cmdHandlerFxn (argIndex, tokenizedArgs);                if (cliStatus == 0)                {                    CLI_write (\"Done\\n\");                }                else                {                    CLI_write (\"Error %d\\n\", cliStatus);                }                break;            }        }        /* Did we get a matching CLI command? */        if (index == gCLI.numCLICommands)        {            /* NO matching command found. Is the mmWave extension enabled? */            if (gCLI.cfg.enableMMWaveExtension == 1U)            {                /* Yes: Pass this to the mmWave extension handler */                cliStatus = CLI_MMWaveExtensionHandler (argIndex, tokenizedArgs);            }            /* Was the CLI command found? */            if (cliStatus == -1)            {                /* No: The command was still not found */                CLI_write (\"'%s' is not recognized as a CLI command\\n\", tokenizedArgs[0]);            }        }    }}"
  },
  
  {
    "title": "TI radar Configuration Command 정리",
    "url": "/posts/ti_radar_config_command/",
    "categories": "Radar",
    "tags": "Radar, Configuration, Command",
    "date": "2022-06-20 00:00:00 +0900",
    





    "snippet": "  참고자료MMWAVE SDK User Guide3D_people_counting_detection_layer_tuning_guideTracking 참고자료TI radar Configuration Command 정리TI의 레이더 소스코드를 보면 사용자가 환경에 따라 변경할만한 파라메타들을 튜닝해서 사용할 수 있도록 cli를 통해 레이더의 동작에 관련된 설정들을 변경할 수 있도록 구현해 놓았다.    일부 파라메타 값을 변경하기 위해서는 위의 chirp diagram에 대한 이해가 필요하다.1. Configuration Command      dfeDataOutputMode(필수로 입력해야 하는 command이며, sensorStop과 sensorStart 사이에서 값을 갱신하면 안되기 때문에 다른 설정 값을 사용하고 싶다면 보드를 재부팅한 후 command를 입력)                  modeType                                            Value              Description                                                          1              프레임에 기반한 chirp 사용 모드                                      2              연속적으로 chirp 쏘기 (xwr68xx에서 지원X)                                      3              고급 프레임 설정 모드                                                channelCfg레이더 안테나 송수신 채널 설정(필수로 입력해야 하는 command이며, sensorStop과 sensorStart 사이에서 값을 갱신하면 안되기 때문에 다른 설정 값을 사용하고 싶다면 보드를 재부팅한 후 command를 입력)                  rxChannelEn사용할 수신 안테나를 지정하기 위한 비트 마스크 값                                            Value              Description                                                          15              0b1111로 마스킹되어 4개 안테나를 모두 사용 (xwr68xx는 4개 안테나 지원)                                                  txChannelEn사용할 송신 안테나를 지정하기 위한 비트 마스크 값                                            Value              Description                                                          7              0b111로 마스킹되어 3개 안테나를 모두 사용 (xwr68xx는 3개 안테나 지원)                                                  cascadingSoC cascading 값                                            Value              Description                                                          0              해당되지 않음                                                adcCfgADC 데이터 포맷 설정(필수로 입력해야 하는 command이며, sensorStop과 sensorStart 사이에서 값을 갱신하면 안되기 때문에 다른 설정 값을 사용하고 싶다면 보드를 재부팅한 후 command를 입력)                  numADCBits                                            Value              Description                                                          0              12-bits                                      1              14-bits                                      2              16-bits (xwr68xx는 16bit만 지원)                                                  adcOutputFmt                                            Value              Description                                                          0              실수 (xwr68xx는 지원X)                                      1              허수 부분을 필터링한 복소수                                      2              허수 부분까지 사용된 복소수                                            adcbufCfgADC 데이터 버퍼의 하드웨어 설정(필수로 입력해야 하는 command이며, sensorStop과 sensorStart 사이에서 값을 갱신 가능)                  subFrameIdx                                            Value              Description                                                          -1              모든 서브 프레임들에 같은 설정 적용 (legacy 모드에서는 -1로 설정해야 함)                                      either              dfeDataOutputMode 를 3(고급 프레임 설정 모드)으로 세팅한 경우 원하는 서브 프레임 번호를 value로 세팅                                                  adcOutputFmtADC 버퍼에서 나갈 데이터의 포맷 설정                                            Value              Description                                                          0              복소수 (xwr68xx는 복소수만 지원)                                      1              실수                                                  SampleSwap샘플링한 IQ 데이터의 I와 Q 순서 설정                                            Value              Description                                                          0              I를 하위, Q를 상위로 저장                                      1              Q를 하위, I를 상위로 저장 (xwr68xx는 1만 지원)                                                  ChanInterleave각각의 안테나에서 수신한 ADC 버퍼 데이터를 안테나 채널을 전환하면서 저장할지 여부를 설정                                            Value              Description                                                          0              인터리빙 패턴에 따라 채널을 전환 (xwr14xx에서만 지원)                                      1              채널을 전환하지 않음 (xwr68xx는 1만 지원)                                                  ChirpThresholdADC 버퍼에서 ping/pong 버퍼 스위치를 트리거하기 위해 사용되는 threshold 구성                                            Value              Description                                                          0 ~ 8              DSP를 사용하여 1D FFT를 수행하는 경우                                      1              DSP가 아닌 HWA에서 1D FFT를 수행하거나 LVDS streaming 사용하는 경우 (xwr68xx는 1만 지원)                                                profileCfg                  profileId프로파일 식별자(아무 값이나 사용 가능하지만, 특별한 것이 없으면 보통 0으로 사용)                                            Value              Description                                                          anything              dfeOutputMode를 1(프레임에 기반한 chirp 사용 모드)로 세팅한 경우, 아무 값이나 사용 가능 (config 당 1개의 유효한 프로파일 지원)                                      anything              dfeOutputMode를 3(고급 프레임 설정 모드)로 세팅한 경우, 아무 값이나 사용 가능 (서브 프레임당 1개의 프로파일이 지원되며, 다른 서브 프레임들은 다른 프로파일들을 가져야 함)                                                  startFreq주파수 변조를 시작할 GHz 단위 주파수 (float로 작성 가능)RampStart에서의 주파수도 해당 주파수가 된다.                                            Value              Description                                                          61.2              61.2GHz에서 시작 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                      77              77GHz에서 시작 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  idleTimeRampEnd와 RampStart 사이에 해당하는 us 단위의 유휴 상태 시간 (float로 작성 가능)Ramp가 끝났기 때문에 다음 Ramp를 준비하기 위해 idleTime 동안 직전 Ramp 에서 증가시켰던 주파수를 다시 startFreq로 내리고 (내려간 주파수가 startFreq에서 흔들리지 않고 안정된 상태가 되어야 함), RampEnd와 함께 off 되었던 TX를 다시 ON 시킨다.                                            Value              Description                                                          7.34              7.34us의 유휴 시간 설정 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                      60.00              60.00us의 유휴 시간 설정 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  adcStartTimeRampStart를 기준으로 설정한 ADC 대기 시간 (float로 작성 가능)RampStart에서 주파수가 높아지기 시작한 후 FrequencySlope가 안정된 구간에서 유효한 ADC 샘플링을 하기 위해 필요하다.                                            Value              Description                                                          17.00              17.00 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  rampEndTimeRampStart를 0초 시작으로 하여 Ramp가 끝나는 us 단위의 시간 설정rampEndTime 동안 주파수가 높아진다.                                            Value              Description                                                          50              50us에 걸쳐 주파수 증가 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  txOutPowerTX 안테나의 송신 출력 파워 차단 코드                                            Value              Description                                                          0              mmW demo에서는 0만 테스트된 상태                                                  txPhaseShifterTX 안테나의 송신 위상 시프터                                            Value              Description                                                          0              mmW demo에서는 0만 테스트된 상태                                                  freqSlopeConstRamp 형태의 chirp에 대한 MHz/us 단위의 주파수 기울기 (float로 작성 가능)chirp 다이어그램의 관계에 따라 다른 profile 파라메타들과 상호의존적으로 설정해야 한다.                                            Value              Description                                                          55.27              chirp의 기울기를 55.27로 설정 (0보다 큰 값을 사용)                                                  txStartTime주파수가 증가하기 시작하는 RampStart를 기준으로 얼만큼의 us 시간 이전에 TX를 시작할 것인지 설정 (float로 작성 가능)chirp 다이어그램의 관계에 따라 다른 profile 파라메타들과 상호의존적으로 설정해야 한다.                                            Value              Description                                                          1              주파수를 증가하기 1us 이전에 TX 안테나에서 송신 시작                                                  numAdcSamplesRampStart와 RampEnd 사이에 있는 StartADCSampling부터 EndADCSampling까지에 해당하는 ADCSamplingTime 동안 수집할 ADC 샘플의 개수 설정(numAdcSamples / digOutSampleRate) = ADCSamplingTime                                            Value              Description                                                          64              64개의 ADC 샘플을 수집 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                      256              256개의 ADC 샘플을 수집 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  digOutSampleRateksps(1초당 1000개의 샘플) 단위의 ADC 샘플링 주파수 설정(numAdcSamples / digOutSampleRate) = ADCSamplingTime                                            Value              Description                                                          2000.00              2MHz의 샘플링 주파수 사용 (chirp 다이어그램의 관계에 따라 어떤 값이든 사용 가능)                                                  hpfCornerFreq1레이더 신호에서 원치 않는 저주파나 클러터를 제거하기 위한 HPF1의 코너 주파수 설정                                            Value              Description                                                          0              HPF1의 코너 주파수를 175kHz로 설정                                      1              HPF1의 코너 주파수를 235kHz로 설정                                      2              HPF1의 코너 주파수를 350kHz로 설정                                      3              HPF1의 코너 주파수를 700kHz로 설정                                                  hpfCornerFreq2레이더 신호에서 원치 않는 저주파나 클러터를 제거하기 위한 HPF2의 코너 주파수 설정                                            Value              Description                                                          0              HPF2의 코너 주파수를 350kHz로 설정                                      1              HPF2의 코너 주파수를 700kHz로 설정                                      2              HPF2의 코너 주파수를 1.4MHz로 설정                                      3              HPF2의 코너 주파수를 2.8MHz로 설정                                                  rxGain수신된 레이더 신호를 증폭할 dB 단위의 RX 이득 값                                            Value              Description                                                          36              RX 이득을 36dB로 설정                                                chirpCfgchirp의 구성 설정(필수로 입력해야 하는 command이며, sensorStop과 sensorStart 사이에서 값을 갱신 가능)                  chirpStartIdxchirp의 시작 인덱스                                            Value              Description                                                          0              TX0을 위한 설정                                      1              TX1을 위한 설정                                      2              TX2을 위한 설정                                                  chirpEndIdxchirp 끝 인덱스                                            Value              Description                                                          0              TX0을 위한 설정                                      1              TX1을 위한 설정                                      2              TX2을 위한 설정                                                  profiledprofile 식별자                                            Value              Description                                                          0              항상 0으로 사용(profileCfg.profileId에서 정의하여 하나의 프로파일만 사용)                                                  startFreqVarHz 단위의 시작 주파수                                            Value              Description                                                          0              0으로 사용 (profileCfg에서 설정하는 것을 추천)                                                  freqSlopeVarkHz/us 단위의 주파수 기울기                                            Value              Description                                                          0              0으로 사용 (profileCfg에서 설정하는 것을 추천)                                                  idleTimeVarus 단위의 유휴 시간                                            Value              Description                                                          0              0으로 사용 (profileCfg에서 설정하는 것을 추천)                                                  adcStartTimeVarus 단위의 ADC 시작 시간                                            Value              Description                                                          0              0으로 사용 (profileCfg에서 설정하는 것을 추천)                                                  txEnableMaskTX 안테나의 enable 마스크개별적인 chirp들은 각각 오직 하나의 TX 안테나에 대해 활성화되어야 한다. (TDM-MIMO 모드)                                            Value              Description                                                          1              0b001로 마스킹되어 TX0을 활성화                                      2              0b010으로 마스킹되어 TX1을 활성화                                      4              0b100으로 마스킹되어 TX2를 활성화                                            lowPower단순히 센서에 전원을 인가하는 것만으로는 RF가 동작하지 않고 cli를 통해 sensor를 start 시켜주어야 센서 데이터를 보내기 시작한다.2. cfg 파일 예시sensorStopdfeDataOutputMode 1channelCfg 15 7 0adcCfg 2 1adcbufCfg -1 0 1 1 1lowPower 0 0profileCfg 0 61.2 60.00 17.00 50 394758 0 55.27 1 64 2000.00 2 1 36chirpCfg 0 0 0 0 0 0 0 1chirpCfg 1 1 0 0 0 0 0 2chirpCfg 2 2 0 0 0 0 0 4frameCfg 0 2 224 400 120.00 1 0dynamic2DAngleCfg -1 5 1 1 1.00 15.00 2dynamicRACfarCfg -1 10 1 1 1 8 8 6 4 4.00 6.00 0.50 1 1staticRACfarCfg -1 4 4 2 2 8 16 4 6 6.01 13.00 0.50 0 0dynamicRangeAngleCfg -1 7.000 0.0010 2 0staticRangeAngleCfg -1 0 1 1antGeometry0 -1 -1 0 0 -3 -3 -2 -2 -1 -1 0 0antGeometry1 -1 0 -1 0 -3 -2 -3 -2 -3 -2 -3 -2antPhaseRot -1 1 -1 1 -1 1 -1 1 -1 1 -1 1fovCfg -1 64.0 64.0compRangeBiasAndRxChanPhase 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0staticBoundaryBox -3 3 -3 3 -0.5 3boundaryBox -5 5 -5 5 -0.5 3.5sensorPosition 3.5 0 90gatingParam 2 2 2 2 4stateParam 3 3 6 300 5 1000allocationParam 2 100 0.01 5 1.5 20maxAcceleration 0.2 0.01 0.2trackingCfg 1 4 800 20 37 33 120presenceBoundaryBox -6 6 -6 6 0.5 4.0sensorStart3. Command 입력TeraTerm 같은 시리얼 통신 프로그램을 통해서 통신 포트(Enhanced COM Port)와 통신 속도(921600)를 지정하여 포트를 오픈한 후 직접 명령어를 입력할 수도 있지만, 맞춰놓았던 설정 값들을 cfg파일에 필요한 command line을 작성해놓고 uart 통신으로 각각의 라인들을 차례대로 입력하면 편리하게 사용할 수 있다.  UART 통신으로 command 입력    import timeimport serial  # pyserialclass Receiver:    def __init__(self):        self.enhanced_port = \"COM6\"        self.standard_port = \"COM5\"        self.cfg_path = \"./people_counting.cfg\"    # 통신 포트 연결    def is_ready(self):        try:            self.uart_com = serial.Serial(port=self.enhanced_port, baudrate=115200, timeout=0)            self.data_com = serial.Serial(port=self.standard_port, baudrate=921600, timeout=0)            return True        except Exception as e:            print(e, \"\\nPlease check serial port\")            return False    # command - acknowledge    def loop(self):        try:            with open(self.cfg_path) as f:                lines = f.readlines()                for line in lines:                    uart_com.write(line.encode())                    ack = uart_com.readline().decode()                    print(ack)                    time.sleep(0.1)                    ack = uart_com.readline().decode()                    print(ack)                    time.sleep(0.1)            self.uart_com.reset_input_buffer()            time.sleep(0.3)        except:            self.uart_com.close()            self.data_com.close()  if __name__ == \"__main__\":    rx = Receiver()    while True:        time.sleep(0.5)        if rx.is_ready():            rx.loop()            break        여기에서 ack = uart_com.readline().decode() 를 연속으로 두 번 호출하는 이유는 명령-응답의 상호 작용을 위한 통신 타이밍을 보장하기 위한 것으로 보여진다. 이와 더불어 line 간에 sleep()도 적절한 통신을 위해 반드시 필요하다.(두 번의 호출 중에 하나의 ack에서만 응답이 들어있음)          readline()을 한번만 사용하고 time.sleep()을 0.2초로 설정한 경우command가 끝까지 출력되지 않고 중간에 끊어지는 문제가 발생하였다.        이외에도 readline()을 연속으로 두 번 호출하면 실제 응답이 아닌 이전 응답이나 불완전한 데이터를 첫 번째 read에서 가져가 버퍼에 존재할 수 있는 원치 않는 데이터를 버리고, 두 번째 호출에서 실제 응답을 읽어들여 ‘오류 처리’나 ‘동기화’에 관련된 방법으로 사용될 수 있다.  "
  },
  
  {
    "title": "Bytes 파싱 참고 노트",
    "url": "/posts/bytes_parsing/",
    "categories": "Radar",
    "tags": "Parsing, Bytes",
    "date": "2022-06-18 00:00:00 +0900",
    





    "snippet": "Bytes Parsing파이썬으로 read한 센서 데이터의 바이트 값을 패킷에 따라 파싱하기 전에 데이터가 정상적으로 들어오는지 print해서 확인해보는 과정에서 출력 결과가 1byte 마다 ‘\\x’로 구분되어 출력되는 것이 아니라 불규칙하게 특수문자들이 포함되어 있는 것을 보았다.어떤 규칙으로 표현되는 것인지를 보면 다음과 같다.1. 바이트 리터럴파이썬에서 바이트 리터럴은 ‘b’ 접두사를 사용하여 정의된 바이트 시퀀스이다.문자열과 비슷하게 보이지만 내부적으로는 각 문자가 8bit 바이트로 표현되는 바이트 값으로 인식된다.2. 바이트 리터럴이 필요한 경우      문자열 인코딩UTF-8과 같이 특정 인코딩을 사용하여 문자열을 바이트로 변환해야 할 때, 바이트 리터럴을 사용        이진 데이터를 다룰 때파일 입출력, 네트워크 통신 등에서 이진 데이터를 다루는 경우에는 바이트 리터럴을 사용합니다. 이는 데이터를 원시적인 바이트 형태로 다루어야 할 때 사용  3. 바이트 리터럴 특수문자 해석 예시      b’\\x04?’2바이트로 이루어진 값으로, 첫 번째 바이트는 0x04이고 두 번째 바이트는 0x3F(물음표)이다.    b’\\x00Ch’                  b’\\x00’ : 1바이트로 이루어진 값으로, 16진수로 표현하면 0x00이고 16진수의 0x00은 10진수로 0이 된다.                    b’C’ : 1바이트로 이루어진 값으로, 16진수로 표현하면 0x43이고 16진수의 0x43은 10진수로 67이 된다. (ASCII 코드에서 ‘C’는 67)                    b’h’ : 1바이트로 이루어진 값으로, 16진수로 표현하면 0x68이고 16진수의 0x68은 10진수로 104가 된다. (ASCII 코드에서 ‘h’는 104)              따라서 각각을 10진수로 변환하면 [0, 67, 104]가 된다.    b’\\xff\\x05a\\x07\\x12\\x07\\xe3\\x05v\\x05’    data = b'\\xff\\x05a\\x07\\x12\\x07\\xe3\\x05v\\x05'  print(data[0], data[1], data[2], data[3], data[4], data[5], data[6], data[7], data[8], data[9])        255 5 97 7 18 7 227 5 118 5          4. bytes와 string 간의 변환  bytes -&gt; stringhex() 함수 사용    data = b'\\xff\\x05a\\x07\\x12\\x07\\xe3\\x05v\\x05'print(data.hex())  # string        ff0561071207e3057605        bytes에서 string으로 변환하면 length는 2배가 된다.    string -&gt; bytesbytes.fromhex() 함수 사용    data = bytes([x for x in range(100)])data_str = data.hex()print(data_str)  # stringprint(bytes.fromhex(data_str))  # bytes        000102030405060708090a0b0c0d0e0f101112131415161718191a1b1c1d1e1f202122232425262728292a2b2c2d2e2f303132333435363738393a3b3c3d3e3f404142434445464748494a4b4c4d4e4f505152535455565758595a5b5c5d5e5f60616263        b'\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f !\"#$%&amp;\\'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abc'          기타for 문을 사용해 string을 bytes로 변환하는 함수를 만들어보았으나 내장함수를 사용하는 것이 압도적으로 빨랐다…(함수를 작성할 때에도 결국 다른 일부 기능의 내장함수들을 돌려 사용해 구현한 것 같은 느낌)fromhex() 함수를 타고 들어가보면 builtins.py에 다음과 같이 작성되어 있다.@classmethod # known casedef fromhex(cls, *args, **kwargs): # real signature unknown; NOTE: unreliably restored from __doc__     \"\"\"    Create a bytes object from a string of hexadecimal numbers.            Spaces between two numbers are accepted.    Example: bytes.fromhex('B9 01EF') -&gt; b'\\\\xb9\\\\x01\\\\xef'.    \"\"\"    pass하위 수준의 언어로 구현되어 있어 해당 기능을 어떻게 구현했는지 바로는 확인해보지 못하는 것 같다.코드도 간결해지고 속도도 빨라지는 것을 보고 무조건 함수를 만들어 사용하는 것보다는 적절한 내장함수를 선택하여 사용하는 것이 효율적이라는 것을 깨달았다. 코드 리팩토링을 할 때 불필요한 코드들을 줄여나가야겠다."
  },
  
  {
    "title": "푸리에 급수(Fourier Series)",
    "url": "/posts/fourier_series/",
    "categories": "Radar",
    "tags": "SignalProcessing, FourierSeries",
    "date": "2022-06-09 00:00:00 +0900",
    





    "snippet": "주기 함수시간 주기(period, T) 마다 반복하는 함수같은 형태를 반복하는 주기를 가진 파동은 아무리 복잡한 파형이라도 $sin$, $cos$ 함수의 결합으로 표현할 수 있다. $$\\begin{aligned}f(t)=a_0&amp;+a_1\\cdot cos(wt)+a_1\\cdot cos(wt)+\\cdots+a_n\\cdot cos(nwt) \\\\&amp;+b_1\\cdot sin(wt)+b_2\\cdot sin(2wt)+\\cdots+b_n\\cdot sin(nwt)\\end{aligned}$$$a_0$는 0이 중심이 아닌 파동을 표현해주며 $cos(0)$는 1이고 $sin(0)$는 0이기 때문에 $b_0$는 생략한다.복잡한 파형이 주기를 가진 파동이기 때문에 이를 만족하려면 단순한 파동들은 모두 기본 주파수의 정수배여야 한다. $$f(t)=a_0+\\displaystyle\\sum_{n=0}^{\\infty}{a_n\\cdot cos(nwt)+b_n\\cdot sin(nwt)}$$$a_n$과 $b_n$은 파동이 얼마나 들어있는가를 의미한다.각 성분이 얼마나 들어있는지 함수의 직교성을 통해 구할 수 있다.함수의 직교성은 내적을 이용 $(f, g) = \\displaystyle\\int_{a}^{b} f(x)\\cdot g(x)dx = 0$ 일 경우,구간 $[a,b]$에서 $f(x)$와 $g(x)$는 orthogonal"
  },
  
  {
    "title": "레이더 신호 이해하기",
    "url": "/posts/radar_signal/",
    "categories": "Radar",
    "tags": "Radar, Signal",
    "date": "2022-05-26 00:00:00 +0900",
    





    "snippet": "  참고 자료(복소 신호)IQ signal레이더 시그널레이더 안테나에서 수신한 신호가 ADC를 거치면 우리는 90도의 위상차를 가진 I데이터와 Q데이터를 얻을 수 있다.      여기서 말하는 IQ 데이터가 무엇인지 이해하기 위해 참고자료를 바탕으로 필요한 배경지식을 정리해보려고 한다.복소 신호(I/Q Signal, Complex Signal, Quadrature Signal)특정 시간에서의 값을 하나의 복소수로 표현할 수 있는 2차원 신호로 I와 Q 2개로 이루어져 있다.  I (In-phase)실수부, Real part  Q (Ouadrature-phase)복소부, Imaginary part복소신호는 전기장과 자기장이 서로 수직하게 전파되는 전자기파와 같은 2차원 신호를 표현할 수 있다.(전기장과 자기장의 2가지 정보를 하나의 수로 동시에 표현 가능, $ cos(wt) + jsin(wt) $)      위의 그림처럼 시간의 흐름에 따라 2개 축에서 동시에 함수가 각각 뻗어 나간다.복소수$ j^2 = -1 $ 로 정의되며,j가 4번 곱해질 때마다 원래의 값으로 돌아오는 주기성을 가지고 있다.(주파수를 지닌 파동이나 신호처럼 주기가 있는 것을 표현할 때 j를 사용 가능)      복소수는 1차원 직선에 존재하는 것이 아니라 임의의 허수축을 추가하여 2차원으로 확장한 복소평면 내에 존재한다.오일러 공식(Euler’s formula)복소수 지수를 정의하는 데에서 출발해서 삼각함수와 지수함수에 대한 관계를 나타내는 공식이다.$$ e^{jϕ} = cos(ϕ) + jsin(ϕ) $$  위 식을 그림으로 나타내면 다음과 같이 이해할 수 있다.      (시간에 따라 원으로 회전하는 복소수의 허수 축 크기를 그리면 $sin$함수가 그려지고, 실수 축 크기를 그리면 $cos$함수가 그려진다.)j의 곱은 phasor form에서 보았을 때 $ e^{jπ/2} $ 를 곱하는 것이므로 반시계방향으로 $ ϕ $에 해당하는 90도씩 회전시킨다.복소수의 성질  Time domain에서 관점2차원의 복소평면에 그린 특정 시점의 복소수를            시간축을 추가해 시간의 흐름에 따라 그려보면 다음 그림과 같이 이해할 수 있다.            복소수가 $f_0$의 주파수로 시간 t의 흐름에 따라 반시계 방향으로 회전하는 형태로 그려진다.여기에서 특정 시점 $t$에반대방향으로 동일하게 회전한 두 phasor를 더하면 cos의 실수부만 남고    $ e^{j2πf_0t} + e^{-j2πf_0t} = 2cos(2πf_0t) $      반대방향으로 동일하게 회전한 두 phasor를 뺴면 sin의 허수부만 남는다.    $ e^{j2πf_0t} - e^{-j2πf_0t} = 2jsin(2πf_0t) $          Frequency domain에서 관점우리가 평소에 보는 $cos(2πf_0t)$와 $sin(2πf_0t)$을 시간 축에 그린다면허수 $j$를 고려하지 않기 때문에 시간에 따라 회전하는 형태의 변화가 실수 성분만 관측되어 그려지지만,주파수 축에서 생각해보면 각각 양과 음의 $f_0$주파수에 해당하는 절반 크기의 임펄스(impulse) 2개로 나타난다.(이로 인해 frequency domain에서 다양한 관점의 해석이 가능해진다.)            $cos(2πf_0t)$은 실수 축에 2개의 임펄스가 좌우대칭으로, $sin(2πf_0t)$은 허수 축에 2개의 임펄스가 원점대칭으로 보인다.    이를 바탕으로 오일러 공식에서 보았던 $cos(2πf_0t) + jsin(2πf_0t)$를 만들어주기 위해 ($ϕ$대신 $2πf_0t$ 사용) $sin$에 $j$를 곱하고 $cos$과 더하면,$sin$의 임펄스가 허수축에서 실수축으로 90도 회전하기 때문에 음의 주파수 쪽은 상쇄되고 양의 주파수 쪽은 1/2로 작아졌던 임펄스 2개가 더해진다.            결과적으로 원래 크기의 실수 임펄스 1개로 합쳐져 주파수 영역에서 $e^{j2πf_0t}$를 나타내는 것을 볼 수 있다.  복소 신호 샘플링$j$의 곱처럼 90도의 변화가 아닌 다른 크기의 위상(phase)의 변화 $ϕ$가 있다면$cos(2πf_0t+ϕ)$는 $\\frac{1}{2}\\cdot(e^{j2πf_0t+ϕ} + e^{-j(2πf_0t+ϕ)})$"
  },
  
  {
    "title": "레이더의 원리",
    "url": "/posts/radar/",
    "categories": "Radar",
    "tags": "Radar",
    "date": "2022-05-15 00:00:00 +0900",
    





    "snippet": "레이더란레이더는 RAdio Detection and Ranging 의 약자로 전파를 사용하여 주변 환경에서 목표물의 거리, 방향, 각도 및 속도를 감지하는 기술이다.방식  단상태 레이더하나의 안테나로 송수신하는 방식을 사용하는 레이더송수전환기(Duplex)를 통해 송신 및 수신 신호를 구분한다.  쌍상태 레이더송신용 안테나와 수신용 안테나를 각각 분리해서 사용하는 방식의 레이더종류  Continuous Wave(CW) 레이더  Frequency Modulated Continuous Wave(FMCW) 레이더  펄스 레이더  기상 레이더  등적용기상 예측, 속도 측정, 장애물 감지, 위치 추적, 등레이더의 원리전파를 방사해서 목표물에서 반사되어 되돌아 온 파를 검출한다.      물체의 색깔이나 형체는 구분하지 못하지만 어둠 속이나 안개 또는 비가 오는 상황에서도 물체를 탐지할 수 있다.기본적으로 수신기(Receiver), 송신기(Transmitter), 안테나(Antenna)로 구성된다.  거리송신된 신호가 다시 되돌아오는 시간으로 구분  상대 속도되돌아 온 신호 주파수의 도플러 변이로 부터 계산비행기, 미사일, 위성, 배, 자동차, 산, 구름, 빗방울 등 목표물에 따라 반사면적(RCS, Radar Cross Section)이 달라지고 목표물에서 반사되어 되돌아오는 파워는 반사면적의 영향을 받는다.  $$ \\text{RCS : 반사면적(σ)} = \\frac{\\text{레이더까지 되반사되어 온 파워}}{\\text{목표물에서 파워 밀도}}&nbsp;[m^2] $$(반사면적은 ‘입력 파워 대비 출력 파워 비’로 계산)RCS가 클 수록 레이더로 되돌아 온 파워의 크기도 커지는데 RCS는 목표물의 실제 크기, 형태, 재질, 입력 파동의 편광과 주파수, 입/반사 각도 등에 영향을 받는다.[형태] 난반사시키는 형태는 RCS를 감소시킴[재질] 나무나 플라스틱은 반사가 작아 RCS가 작고 금속은 RCS가 큼[주파수] 입력 파동의 주파수가 높을 수록 투과성은 떨어지지만 RCS가 커짐"
  },
  
  {
    "title": "C언어 매크로 정리",
    "url": "/posts/c_macro/",
    "categories": "Embedded",
    "tags": "C, Macro",
    "date": "2022-04-20 00:00:00 +0900",
    





    "snippet": "CC언어에서 해시 기호 ‘#’은 전처리 지시어로 사용된다.전처리 지시문과 함께 사용되며, 컴파일하기 전 전처리 단계에서 전처리기에 의해 ‘#전처리 지시문’에 따라 텍스트 대체 및 코드 생성 과정을 통해 코드가 수정된다.수정된 코드는 구문 검사, 최적화, 실행 파일 생성과 같은 컴파일 단계를 위해 컴파일러로 전달된다.1. 헤더 포함  #include프로그램에서 헤더 파일을 포함하기 위해 사용하는 지시문으로 외부 코드 파일이나 라이브러리를 프로그램에게 포함한다.    #include &lt;stdio.h&gt;#include \"myheader.h\"                      &lt; &gt;전처리기가 미리 정의된 표준 시스템 디렉토리에서 헤더 파일을 검색한다.일반적으로 표준 라이브러리 헤더, 컴파일러나 운영 체제에서 제공하는 헤더를 포함하는데 사용한다.                    ” “전처리기가 현재 디렉토리 또는 컴파일러의 검색 경로에 지정된 디렉토리에서 헤더 파일을 검색한다.일반적으로 사용자가 프로젝트의 일부로 작성했거나 특정 디렉토리에 있는 헤더를 포함하는데 사용된다.            2. 매크로 정의  #define매크로 인수를 문자열 리터럴로 변환하는 문자열화를 수행    #define PI   3.141592        #define STRINGIFY(x) #x  // 문자열 리터럴로 변환        #include &lt;stdio.h&gt;#ifdef DEBUG_MODE#define DebugP_assert(expression) \\  // 디버그 매크로 정의    do { \\        if (!(expression)) { \\            printf(\"Assertion failed: %s, line %d\\n\", __FILE__, __LINE__); \\            printf(\"Expression: %s\\n\", #expression); \\            abort(); \\        } \\    } while (0)#else#define DebugP_assert(expression) ((void)0)#endifint main() {    DebugP_assert ((uint32_t)(gMmwMssMCB.frameStatsFromDSP) != SOC_TRANSLATEADDR_INVALID);    return 0;}                      FILE                    LINE소스 코드의 현재 줄 번호를 나타내는 매크로디버깅 또는 오류 보고 목적으로 사용된다.                    abort()프로그램을 갑자기 종료시키는 함수일반적으로 프로그램에서 복구할 수 없는 오류나 예외적인 조건이 발생할 때 호출된다.            3. 조건부 컴파일      #ifdef매크로나 식별자가 정의된 경우 #ifdef 블록 내의 코드가 컴파일 된다.        #ifndef매크로나 식별자가 정의되지 않은 경우 #ifndef 블록 내의 코드가 컴파일 된다.        #endif조건부 블록의 끝    #ifndef CONFIG_H#define CONFIG_H  /******************** *   헤더 파일 작성 ********************/  #endif /* CONFIG_H */            #if표현식이 0이 아닌 값이면 #if 블록 내의 코드가 컴파일 된다.        #elif추가 조건의 표현식이 0이 아닌 값이면 #elif 블록 내의 코드가 컴파일 된다.        #else앞의 조건이 모두 해당되지 않으면 #else 블록 내의 코드가 컴파일 된다.    #define MMWDEMO_CLI_TASK_PRIORITY                 2#define MMWDEMO_DPC_OBJDET_DPM_TASK_PRIORITY      5  #if (MMWDEMO_CLI_TASK_PRIORITY &gt;= MMWDEMO_DPC_OBJDET_DPM_TASK_PRIORITY)System_printf (\"CLI task priority must be &lt; Object Detection DPM task priority\\n\");#elif (MMWDEMO_CLI_TASK_PRIORITY &lt;= 1)System_printf (\"CLI task priority must be &gt; 1\\n\");#elsePcount3DDemo_CLIInit(MMWDEMO_CLI_TASK_PRIORITY);      4. 기타      #error명시적인 피드백을 제공하기 위해 지정된 오류 메시지와 함께 컴파일 오류를 생성하여 컴파일 프로세스를 중지한다.        #pragma컴파일러에 명령을 하는 지시문으로 지시문 뒤에 특정 pragma 키워드와 필요한 매개변수가 온다.    #define MMWDEMO_OBJDET_LOCALRAM_SIZE (8U * 1024U)uint8_t gDPCTCM[MMWDEMO_OBJDET_LOCALRAM_SIZE];#pragma DATA_SECTION(gDPCTCM, \".dpcLocalRam\");#pragma DATA_ALIGN(gDPCTCM, 4);          typedef  Handlevoid * 유형은 가리키는 개체의 유형을 지정하지 않고 모든 개체의 주소를 보유할 수 있어서 다른 유형의 개체를 참조할 수 있는 불투명 핸들을 만들기 위해 자주 사용된다.```c/** SOC_init()에서 반환되는 값의 유형을 명시적으로 지정하지 않고          포인터로 사용하여 return 값이 어떤 종류인지 필수적인 파라메타가      포함되어 있는 구조체인지 등을 파악하기 힘들다.  /typedef void SOC_Handle;        SOC_Handle      socHandle;socHandle = SOC_init (&amp;socCfg, &amp;errCode);```    함수 포인터런타임에 함수 포인터를 전달하거나 동적으로 함수를 할당해야 하는 경우 사용    // 함수 포인터 유형 정의typedef int32_t (*HandlerPtr)(int32_t argc, char* argv[]);  // 함수 포인터 변수 선언HandlerPtr functionPtr;int32_t CLI_ADCBufCfg(int32_t argc, char* argv[]) {    /********************     *     함수 작성     ********************/}int main() {    // 함수 포인터 할당    functionPtr = CLI_ADCBufCfg;          // 함수 포인터 호출    int32_t result = functionPtr(2, [\"arg1\", \"arg2\"]);      return 0;}                      (*HandlerPtr)HandlerPtr을 포인터 유형으로 선언                    (int32_t argc, char* argv[])포인터가 가리킬 함수의 매개변수와 해당 유형 정의              함수 포인터와 구조체    // 함수 포인터 유형 정의typedef int32_t (*CLI_CmdHandler)(int32_t argc, char* argv[]);  // 구조체 정의typedef struct CLI_CmdTableEntry_t{    char* cmd;    char* helpString;    CLI_CmdHandler cmdHandlerFxn;  // 함수 포인터 변수 선언} CLI_CmdTableEntry;  // 구조체 포인터 변수 선언CLI_CmdTableEntry* ptrCLICommandEntry;  // cmdHandlerFxn에 할당할 함수 정의int32_t MyCommandHandler(int32_t argc, char* argv[]){    /********************     *     함수 작성     ********************/    return 0;}  int main(){    // 함수 포인터 할당    ptrCLICommandEntry-&gt;cmdHandlerFxn = MyCommandHandler;      // 할당한 함수 포인터 사용    int32_t argc = 3;    char* argv[] = {\"arg1\", \"arg2\", \"arg3\"};    int32_t cliStatus = ptrCLICommandEntry-&gt;cmdHandlerFxn(argc, argv);      return 0;}      Handle과 Handler      핸들(Handle)개체 또는 리소스에 대한 추상 데이터 유형으로 개체에 대한 고유 식별자, 참조 역할을 하는 불투명 값메모리, 파일, 네트워크 연결, 하드웨어 장치와 같은 리소스에 대한 액세스를 캡슐화하고 제어하는 데 사용된다. 핸들을 사용하면 내부 세부 정보를 노출하지 않고 개체에 대한 작업을 수행할 수 있다.        핸들러(Handler)이벤트를 처리하거나 이벤트 또는 요청에 대한 응답으로 특정 작업을 수행하는 소프트웨어 구성 요소특정 이벤트를 처리하도록 설계되어 트리거 시 원하는 기능을 실행한다.  "
  },
  
  {
    "title": "C언어 코드 관련 정리",
    "url": "/posts/c/",
    "categories": "Embedded",
    "tags": "Handler, Interrupt",
    "date": "2022-04-17 00:00:00 +0900",
    





    "snippet": "Handler임베디드 시스템에서 handler는 이벤트나 인터럽트 등의 외부적인 요인으로부터 처리해야할 일이 발생했을 때, 이를 처리하기 위한 함수나 코드 블록을 가리키는 포인터를 말한다.주로 장치 드라이버, 운영 체제, 응용 프로그램 등에서 사용되며 이벤트나 인터럽트가 발생 시 매우 빠른 속도로 처리해야하기 때문에 최적화가 필요하다.예를 들어, 인터럽트 핸들러는 특정 인터럽트가 발생했을 때 호출되는 함수를 가리키는 포인터가 된다.이러한 핸들러가 가리키는 특정 기능을 구현한 함수는 프로젝트에 따라 다르지만 일반적으로 시스템의 핵심 기능을 담당하기 때문에 보안 및 안정성 등의 이유로 공개되어 있지 않다.함수 호출의 오버헤드란?함수가 호출되면 프로그램은 반환 주소 저장, 지역 변수용 스택 공간 할당, 함수 호출 스택 프레임 설정과 같은 작업을 수행하는데 이 때, 인라인으로 직접 실행하는 것에 비해 필요한 추가 시간과 리소스를 말한다.간단한 함수나 호출 수가 적은 프로그램에서는 큰 차이가 없어보일 수 있으나 성능이 중요한 경우나 자주 호출되는 함수에서는 함수 호출의 오버헤드가 누적되어 프로그램의 전체 성능에 영향을 미칠 수 있다.오버헤드를 줄이고 성능을 향상시키기 위해 포인터를 사용하거나 인라인 함수를 사용한다.인라인 함수컴파일러에게 함수 호출 부분을 호출하는 대신 함수의 실제 코드로 대체하도록 지시하는 프로그래밍 구조이다.함수의 코드가 호출되는 위치에 직접 삽입되기 때문에 함수 호출의 오버헤드를 없앨 수 있다.특정 상황에서 성능을 향상시킬 수 있지만 코드 크기를 증가시킬 수도 있기 때문에 코드 크기와 성능 향상 사이의 균형을 고려하려 신중히 사용하여야 한다.inline 키워드를 사용해 함수를 인라인으로 지정할 수 있지만 이것은 컴파일러에 대한 제안일 뿐이기 때문에 컴파일러의 최적화 및 제약 사항에 따라 실제로 함수가 인라인으로 처리되지 않을 수도 있다.인터럽트#include &lt;stdint.h&gt;#include &lt;stdbool.h&gt;// 인터럽트 함수임을 알리는 매크로#define INTERRUPT_HANDLER __attribute__((interrupt))// inline 함수로 정의static inline void myInterruptHandler(void) {    // 인터럽트 발생 시 실행되는 코드}// 인터럽트 함수로 등록void registerInterruptHandler(void) {    // 인터럽트 핸들러 등록    INTERRUPT_HANDLER void (*intHandler)(void) = &amp;myInterruptHandler;        // 인터럽트 레지스터에 핸들러 등록    // ...}"
  },
  
  {
    "title": "임베디드 리눅스 참고",
    "url": "/posts/embedded_linux/",
    "categories": "Embedded",
    "tags": "Embedded, Linux",
    "date": "2022-04-14 00:00:00 +0900",
    





    "snippet": "Linux  BootLoader  Kernel한가지를 공통으로 사용하지만 버전이 중요  File SystemUbuntu, CentOS, …OS  Multi Process  Memory  File System부트로더운영체제(OS)가 시동되기 이전에 미리 실행되면서 커널이 올바르게 시동되기 위해 필요한 모든 관련 작업을 마무리하고 최종적으로 운영체제를 시동시키기 위한 목적을 가진 프로그램메모리, 하드웨어(네트워크, 프로세서 속도, 인터럽트), 코드/데이터/스택 영역 설정 및 초기화, 커널 로더와 커널 이미지를 로딩, 커널 로더를 실행하여 커널 이미지가 실행되도록 함하드웨어 의존성이 강한 코드들로 되어 있고(대부분 어셈블리언어로 작성 됨) 프로그래머는 프로세서 구조(Clock, UART, Ethernet 등), 특징, 사용법에 대해 잘 알고 있어야 작업 가능부트로더 종류  LILOLInux LOader, 리눅스에서 사용되었으며, GRUB를 기본 부트로더로 사용하기 전까지 리눅스 배포판에서 사용하던 기본 부트로더  GRUBGRand Unified Bootloader, GNU 프로젝트의 부트로더이며, 현재 대부분의 리눅스 배포판에서 사용, a.out와 ELF 포멧 지원, BIOS에서 인식되는 모든 장치에 액세스 가능  BLOBBoot Loader OBject, ARM용 부트로더로 임베디드 리눅스 상에서 LILO와 같이 선택 부팅이 가능하도록 기능 제공하며, 리눅스 커널 다운로드를 시리얼 케이블을 이용할 수 있도록 제공  ARMBOOTStrongARM을 위한 공개 소스 펌웨어, 다중형 플래시 메모리 지원, tftp, PCMCIA CF 부트등을 지원  RedBootRedHat에서 개발한 임베디드 운영체제인 eCOS를 기반으로하여 만든 부트로더  U-BOOTUniversal BOOTloader, 주로 PowerPC와 ARM 임베디드 시스템에서 사용되는 부트로더이며 오픈소스          깃허브 소스트리https://github.com/u-boot/u-boot      U-Boot장치에서 U-Boot 모드로 들어가서 명령 프롬프트에 액세스하려면 전원을 켜고 부팅 프로세스를 ‘Ctrl+C’ 등으로 중단하면 된다.명령 프롬프트를 통해 명령어를 입력하여 부트로더와 상호작용하고 설정을 구성하거나 이미지를 로드하는 등의 작업을 수행할 수 있다."
  },
  
  {
    "title": "우분투에서 Docker 사용하기",
    "url": "/posts/docker_ubuntu/",
    "categories": "Docker",
    "tags": "Docker, Docker-Compose, Ubuntu, Kafka, InfluxDB",
    "date": "2022-02-03 00:00:00 +0900",
    





    "snippet": "우분투에서 도커 사용하기  운영 체제Ubuntu 20.04 LTS  컨테이너          Zookeeper      Kafka      InfluxDB      Kafka-Consumer &amp; InfluxDB write      1. docker 설치(docker 설치 방법)2. docker-compose 설치(docker-compose 설치 방법)3. sudo 권한 없이 docker 명령어 실행하기(방법)4. Kafka, Influxdb 서버 구축zookeeper, kafka, influxdb는 공개되어 있는 이미지를 다운받아 베이스 이미지로 사용  docker-compose.yml    version: '2.5.0'services:  zookeeper:    image: wurstmeister/zookeeper    container_name: zookeeper    ports:      - \"2181:2181\"    restart: always  kafka:    image: wurstmeister/kafka    container_name: kafka    ports:      - \"9092:9092\"    environment:      KAFKA_ADVERTISED_HOST_NAME: 211.197.16.44      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181    volumes:      - /var/run/docker.sock:/var/run/docker.sock    restart: always  influxdb:    image: influxdb:2.0    container_name: influxdb    ports:      - \"8086:8086\"    volumes:      - type : bind        source: /media/petabrew/hdd1/var/lib/influxdb/data        target: /var/lib/influxdb2      - type: bind        source: /media/petabrew/hdd1/var/lib/influxdb/config        target: /etc/influxdb2    restart: always        [컨테이너 백그라운드 실행]    docker-compose up -d          5. 소스코드 실행  run.sh    python3 /app/kafka_consumer_raw/main.py &amp;python3 /app/kafka_consumer_target/main.py        ‘&amp;’를 붙이면 파이썬 파일을 백그라운드로 실행하여 컨테이너에서 2개의 파이썬 코드를 동시에 실행시킬 수 있다.    Dockerfile    FROM python:3.8COPY /kafka_consumer_raw/ /app/kafka_consumer_raw/COPY /kafka_consumer_target/ /app/kafka_consumer_target/COPY run.sh /app/RUN pip install kafka-python==2.0.2 influxdb-client==1.35WORKDIR /appCMD [\"/bin/bash\", \"/app/run.sh\"]        [도커 이미지 빌드]    docker build -t {image_name} .        [빌드한 이미지로 컨테이너 생성 및 실행]    docker run --name {container_name} -p 5001:80 -d --restart always {image_name}        호스트 머신의 5001 포트가 컨테이너 내부의 80 포트로 매핑되도록 지정컨테이너가 중지되면 백그라운드로 항상 재시작  "
  },
  
  {
    "title": "Docker 명령어 정리",
    "url": "/posts/docker_command/",
    "categories": "Docker",
    "tags": "Docker, Docker-Compose, Command",
    "date": "2022-01-21 00:00:00 +0900",
    





    "snippet": "도커 명령어Docker command-line referencehttps://docs.docker.com/engine/reference/commandline/cli/Docker  도커 버전 확인    docker --version          Docker Image  도커 이미지 검색    docker search {image}        도커 이미지 다운로드    docker pull {image_name:tag}        (tag의 default 값은 latest)docker hub에 공개되어 있는 이미지를 다운받는다. (레지스트리 서버의 default 도메인 : dockerhub)    현재 Host 머신에 존재하는 이미지 목록 확인    docker images        특정 이미지 삭제    docker rmi {image_repository:tag}        docker rmi {image_id}        image_id를 통해 이미지를 삭제할 때 같은 image_id를 가진 리포지토리들이 여러 개 태그되면 오류가 발생한다. (force 옵션을 통해 강제로 해결 가능)    특정 이미지 강제 삭제    docker rmi -f {image_id}        해당 image_id를 가진 이미지들이 모두 삭제된다.  Dockerfile  Dockerfile을 통한 이미지 빌드    docker build -t {image_name} .        Dockerfile을 다른 파일명으로 작성 후 이미지 빌드    docker build -t {image_name} -f {Dockerfile_name} .        명령어 마지막에 ‘.’ 은 Dockerfile이 있는 현재 디렉토리로 빌드 컨텍스트가 된다.빌드 컨텍스트를 기준으로 상위 폴더로 올라가게 되면 빌드 컨텍스트에서 벗어나는 것이므로 오류 발생의 원인이 된다.(ex. Dockerfile 내 COPY 명령문에서 상대경로 작성 시 현재 디렉토리나 하위 디렉토리만 사용)  Docker Container  실행중인 컨테이너 목록 조회    docker ps        컨테이너 전체 목록 조회    docker ps -a        컨테이너 생성    docker create -it --name {container_name} {image_repository}                                Option          Description                                      -i          사용자가 입출력을 할 수 있는 상태로 설정 (interactive)                          -t          가상 터미널 환경을 에뮬레이션                      컨테이너 삭제     docker rm {container_name}        컨테이너 실행    docker start {container_name}        컨테이너 종료    docker stop {container_name}        컨테이너 생성 및 실행 시작, 포트포워딩    docker run -itd --name {container_name} -p {host_port}:{container_port} {image_repository} /bin/bash        호스트 IP의 포트로 접근하면 컨테이너의 포트로 연결된다.                            Option          Description                                      -d          일반 프로세스가 아닌 데몬 프로세스(백그라운드) 형태로 실행해 프로세스가 끝나도 컨테이너 유지                      호스트 머신의 파일을 컨테이너 안으로 복사    docker cp {host_file_path} {container_name}:{container_path}        컨테이너 안에 있는 파일을 호스트 머신으로 복사    docker cp {container_name}:{container_path} {host_file_path}        특정 컨테이너 접속    docker exec -it {container_name} /bin/bash        /bin/bash 프로세스가 생성된다.    컨테이너 유지 및 접속 종료    ctrl + P, ctrl + Q        컨테이너 종료 및 접속 종료    exit        ctrl + D          포트가 이미 바인딩 되어 있어서 프로그램을 실행할 수 없는 경우  특정 포트를 사용하는 프로세스 찾기    sudo lsof -i :{port}        강제 종료    sudo kill -9 {pid}          Docker-Compose  도커 컴포즈 버전 확인    docker-compose --version          docker-compose.yml  docker-compose.yml 파일에 작성된 컨테이너 생성 및 백그라운드 실행    docker-compose up -d        사용자 지정 파일명.yml 파일에 작성된 컨테이너 생성 및 백그라운드 실행    docker-compose -f {file_name.yml} up -d        docker-compose.yml 파일이 존재하는 경로로 이동하여 실행한다.  "
  },
  
  {
    "title": "도커(Docker)",
    "url": "/posts/docker/",
    "categories": "Docker",
    "tags": "Docker Image, Docker Container",
    "date": "2022-01-16 00:00:00 +0900",
    





    "snippet": "Docker란소프트웨어 개발자가 Linux 컨테이너를 만들고 사용할 수 있도록 하는 컨테이너 기반의 오픈 소스 가상화 플랫폼개발자는 Docker를 사용하여 애플리케이션을 종속성과 함께 단일 컨테이너로 패키징하여 다양한 컴퓨팅 환경에서 일관성과 이식성을 보장할 수 있다. 또한, 소프트웨어 개발 수명 주기를 간소화하고 리소스 활용도를 개선하며 확장성을 향상할 수 있다.    1. 도커 이미지(Docker Image)도커 컨테이너 생성 및 실행에 필요한 코드, 런타임, 시스템 도구, 라이브러리 및 종속성을 포함하여 애플리케이션을 실행하는데 필요한 모든 것을 포함하는 독립 실행형 실행 패키지이미지는 특정 시점의 가상 환경과 애플리케이션을 나타내는 스냅샷으로 변경 불가한(immutable) 읽기 전용 파일이다. 이러한 이미지는 자체로 실행되는 것은 아니고 런타임 환경을 위한 템플릿으로 사용된다. 덕분에 일관성이 보장되어 개발자는 동일한 조건에서 소프트웨어를 실행할 수 있다.2. 도커 이미지 리포지토리2-1. 도커 레지스트리(Docker Registry)도커 이미지의 저장 및 배포 시스템도커 레지스트리를 사용하면 조직에서 내부적으로 도커 이미지를 저장하고 공유하는 자체 개인 리포지토리를 호스팅하고 관리할 수 있다.(민감하거나 독점적인 이미지를 유지하여 보안을 강화)2-2. 도커 허브(Docker Hub)빌드한 컨테이너 이미지를 저장하고 다른 사람과 공유할 수 있는 중앙 집중식 리포지토리(Docker에서 제공하는 클라우드 기반 공용 레지스트리의 특정 구현) (커뮤니티 기반 플랫폼 역할)도커 허브를 통해 도커 이미지의 버전 관리 및 배포가 가능하다.3. Dockerfile도커 이미지를 생성하기 위한 스크립트애플리케이션의 환경과 종속성을 정의하여 다양한 개발, 테스트 및 프로덕션 환경에서 일관된 배포가 가능하다.배포 시 용량이 큰 이미지 파일보다는 Dockerfile 만 배포한 후 실행시켜 사용하도록 하면 편리하게 배포할 수 있다.  Dockerfile 작성법    FROM {베이스 이미지:태그}COPY {호스트 머신의 경로/파일 or 경로/폴더/} {이미지 내부의 경로 or 경로/폴더/}RUN {이미지를 빌드하는 과정에서 실행할 명령어}  # 패키지 설치, 파일 다운로드, 코드 컴파일 같이 이미지 종속성 및 환경 구성WORKDIR {컨테이너 내에서 작업할 디렉토리 설정}  # 베이스 이미지에 따라 이미 생성되어 있는 폴더가 있음CMD [{\"인터프리터\"}, {\"실행할 명령\"}]          # 컨테이너가 실행될 때 실행할 명령        도커는 Dockerfile에 나열된 명령문을 차례대로 수행하면서 이미지를 생성한다.COPY 명령문의 경우 호스트 머신 쪽에 폴더를 지정하면 폴더 내의 파일들이 모두 복사되므로, 이미지 내부 경로에 복사할 폴더의 이름을 작성해주면 기존 경로에 폴더가 생성되면서 폴더 및 폴더 내 파일들이 통째로 들어있게 된다.  4. 도커 컨테이너(Docker Container)애플리케이션을 실행하는 데 필요한 모든 필수 소프트웨어, 라이브러리 및 종속성을 포함하는 가볍고 격리된 환경이미지를 기반으로 여러 컨테이너를 생성할 수 있고, 컨테이너가 삭제되더라도 컨테이너를 생성할 때 사용한 이미지는 그대로 남아있다. (컨테이너는 이미지의 인스턴스 개념)컨테이너는 매우 가벼운 모듈식 가상 머신처럼 다룰 수 있으며 구축, 배포, 복사, 다른 환경으로 이동을 통해 애플리케이션을 클라우드에 최적화할 수 있다. 기본 운영 체제나 인프라에 관계없이 Docker를 지원하는 모든 시스템에서 배포 및 실행이 가능하다.컨테이너를 생성하면 읽기 전용 베이스 이미지 위에 쓰기 가능한 레이어가 추가되어 수정이 가능해진다.이미지 베이스는 별도로 존재하며 변경할 수 없고 컨테이너를 실행할 때 컨테이너 내부에 해당 파일 시스템(도커 이미지)의 읽기-쓰기 복사본을 만들어 컨테이너 레이어를 추가한다.하나의 베이스 이미지에서 무제한으로 도커 이미지를 생성할 수 있다.이미지의 초기 상태를 변경하여 저장할 때마다 이미지 레이어를 추가하여 새 템플릿을 만든다. 새로 추가된 레이어는 이전 레이어에서 비롯되어 만들어진다. 따라서 도커 이미지는 여러 개의 레이어로 구성될 수 있으며, 이미지 계층은https://sunrise-min.tistory.com/entry/Docker-Container%EC%99%80-Image%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80Docker Compose란다중 컨테이너 Docker 애플리케이션을 정의하고 실행하기 위한 도구하나의 프로젝트를 진행하는데 여러 개의 컨테이너를 사용하는 경우, 각각의 컨테이너들을 번거롭게 개별적으로 컨트롤할 필요 없이 한번에 관리할 수 있도록 작업을 단순화한다.1. docker-compose.yml도커 컴포즈에서 사용하는 구성 파일서비스, 구성, 종속성 및 관계를 지정하여 여러 Docker 컨테이너를 단일 애플리케이션으로 정의하고 관리할 수 있게 해준다.  docker-compose.yml 작성법    version: {'설치한 도커 컴포즈의 버전'}services:  {서비스 명}:    image: {사용할 베이스 이미지:태그}    container_name: {생성할 컨테이너의 이름}    ports:      - \"2181:2181\"    restart: always      "
  },
  
  {
    "title": "구조체(Structure)",
    "url": "/posts/structure/",
    "categories": "C",
    "tags": "structure",
    "date": "2021-11-07 00:00:00 +0900",
    





    "snippet": "개념struct Score {    char name[10];    int kor;    int mat;    int eng;} S;"
  },
  
  {
    "title": "포인터(Pointer)",
    "url": "/posts/pointer/",
    "categories": "C",
    "tags": "pointer",
    "date": "2021-11-02 00:00:00 +0900",
    





    "snippet": "C언어에서 함수는 값에 의한 호출만 이루어지지만 포인터를 이용해 주소에 의한 호출로 참조에 의한 호출과 같은 효과를 낼 수 있다.함수 호출 방식  값에 의한 호출 (call by value)함수를 호출한 곳에서 호출된 함수의 매개변수로 실인자의 값을 복사해서 전달하는 방식void call_by_value(int val){    val = 100;}int main(){    int num = 10;    call_by_value(num);    printf(\"%d\\n\", num);        return 0;}지역변수 val은 함수가 종료되면서 삭제된다.10  주소에 의한 호출 (call by address)함수를 호출한 곳에서 호출된 함수의 매개변수로 실인자의 주소값을 복사해서 전달하는 방식C언어에서는 선언할 때 포인터 연산자(*)를 사용void call_by_address(int* addr){    *addr = 100;}int main(){    int num = 10;        call_by_address(&amp;num);    printf(\"%d\\n\", num);    return 0;}100  참조에 의한 호출 (call by reference)C++ 함수에서 함수 외부 메모리 공간을 참조할 때 사용C++에서는 선언할 때 역참조연산자(&amp;)를 사용void call_by_reference(int&amp; ref){    b++;}int main(){    int num = 10;        call_by_reference(num);    printf(\"%d\\n\", num);    return 0;}11메모리 구조  코드(code) 영역  데이터(data) 영역  스택(stack) 영역  힙(heap) 영역이중 포인터#include &lt;stdio.h&gt;void call_by_value(int val){    val = 100;}void call_by_address(int *addr){    *addr = 100;}int main(){    int value = 5;    int address = 5;    printf(\"[before] value : %d, address : %d\\n\", value, address);    call_by_value(value);    call_by_address(&amp;address);    printf(\"[after] value : %d, address : %d\\n\", value, address);}[before] value : 5, address : 5[after] value : 5, address : 100int global_value = 80;void call_by_value(int* val){    val = &amp;global_value;}void call_by_address(int** addr){    *addr = &amp;global_value;}"
  },
  
  {
    "title": "Git 명령어 정리",
    "url": "/posts/git_command/",
    "categories": "Git",
    "tags": "Git, Github, Command",
    "date": "2021-10-11 00:00:00 +0900",
    





    "snippet": "개념Git컴퓨터 파일의 변경사항을 추적하고 여러 명의 사용자들 간에 해당 파일들의 작업을 조율하기 위한 분산 버전 관리 시스템(자신의 환경에 맞게 별도로 설치 필요)Github원격 저장소Git 명령어Check  현재 상태 확인    git status        수정 사항 및 상태를 확인할 수 있다.    전체 로그 확인    git log        커밋 로그들과 각 해시 값을 확인할 수 있다.로그가 많은 경우에는 ‘enter’를 통해 다음 라인을 확인할 수 있으며, ‘q’로 빠져나올 수 있다.  Config  config 리스트 확인    git config --list        push용 사용자 이름 설정    git config --global user.name \"{username}\"        push용 이메일 설정    git config --global user.email \"{id@email.com}\"        깃을 처음 설치한 상태에서는 username과 email이 세팅되어 있지 않으므로 push할 때 사용할 이름과 이메일을 알려주어야 한다.‘–global’ 옵션을 통해 특정 프로젝트가 아닌 전체 깃에 적용하면 한번만 작업해주면 된다.    config의 사용자 이름 삭제    git config --unset --global {username}        config의 이메일 삭제    git config --unser --global {user.email}      Remote Repository  등록된 원격 저장소 이름 확인    git remote        원격 저장소 확인    git remote -v        push용과 fetch용 주소도 알려준다.    특정 원격 저장소의 자세한 정보 확인    git remote show {name}        원격 저장소 등록    git remote add {name} {HTTPS or SSH}        등록된 원격 저장소의 이름 변경    git remote rename {name} {modified name}        등록된 특정 원경 저장소 제거    git remote rm {name}      Branch check  로컬 저장소의 브랜치 확인    git branch        원격 저장소의 브랜치 확인    git branch -r        로컬 및 원격 저장소의 브랜치 확인    git branch -a      Branch  브랜치 생성하기    git branch {branch}        원격 브랜치 업데이트    git remote update        원격 브랜치 가져오기    git checkout -t {origin/branch}        브랜치 이동하기    git switch {branch}        git 2.23 버전 이후에는 ‘git checkout’ 대신 ‘git switch’를 사용한다.    브랜치를 만들면서 브랜치 변경    git switch -c {branch}      Branch delete  브랜치 삭제    git branch -d {branch}        브랜치 강제 삭제    git branch -D {branch}      Download  깃 저장소 생성하기    git init        ‘.git’ 파일이 생성되면서 해당 폴더가 로컬 리포지토리가 된다.    저장소 복제 및 다운로드    git clone {HTTPS or SSH}        원격 저장소를 ‘리포지토리 명’ 폴더로 통째로 복제하고 원격 주소를 연결한다.    원격 저장소의 변경 내용을 현재 디렉토리로 가져오기    git pull {HTTPS or SSH}        세팅되어 있는 원격 주소를 사용해서 가져온다.  Upload  저장소에 변경사항 추가 (파일 지정)    git add {file} {file} ...        저장소에 변경사항 모두 추가 (.gitignore에 기재된 것을 고려)    git add .        저장소에 변경사항 모두 추가 (.gitignore에 기재된 것을 고려하지 않음)    git add *        Staging Area에 add한 파일을 내리기    git reset {file}        ’–mixed’ 옵션이 default로 되어있다.    파일의 수정 내역을 이전 버전으로 되돌리기    git checkout --{file}        저장해놓은 파일의 수정 내역이 사라진다.    커밋 생성    git commit -m \"{message}\"        커밋 메시지 수정    git commit --amend        unix 편집기를 통해 수정할 수 있다.(‘a’ : insert)(‘esc + wq!’ : 저장 후 나가기)    변경 사항 원격 서버 업로드    git push origin {branch}        origin 주소의 리포지토리로 업로드한다.  Merge  마지막 pull 이후 원격 저장소 또는 브랜치에 적용된 변경사항 확인    git fetch        merge 하기 전에 변경 내용 비교    git diff {branch} {another branch}        현재 브랜치에 다른 브랜치 수정사항 병합    git merge {another branch}      Version  특정 커밋 버전으로 이동    git reset --soft {hash}        특정 커밋 버전으로 되돌리며 이후 커밋 삭제    git reset --hard {hash}        커밋 로그들도 같이 사라진다.    원격 저장소에 로컬 저장소 버전을 강제로 저장    git push -f        버전 이동 시 로컬 저장소와 원격 저장소의 내용이 달라 그냥 push 되지 않을 경우 사용한다.  "
  },
  
  {
    "title": "유용한 사이트 링크",
    "url": "/posts/site/",
    "categories": "Blog",
    "tags": "Site",
    "date": "2021-10-01 00:00:00 +0900",
    





    "snippet": "      참고자료(복소 신호)IQ signal 푸리에 급수 FFTFFT 정리FFT 구현FIR FilterWindow    파이썬 튜토리얼1    에너지신호/전력신호IQ Sampling    머신러닝 강좌1머신러닝 강좌2머신러닝 강좌3Yolo custom데이터 사이언스 스쿨TI Resource Explorer무료강좌PDF 분석 툴시계열 데이터 처리Chat PDF유튜브 요약컨퍼런스 검색뤼튼  "
  },
  
  {
    "title": "깃허브 블로그 시작하기",
    "url": "/posts/github_blog_chirpy/",
    "categories": "Blog",
    "tags": "Git, Github, Blog",
    "date": "2021-09-19 00:00:00 +0900",
    





    "snippet": "{GH_USERNAME}.github.io 리포지토리를 생성하여 블로그를 만들면,테마를 적용하기 위해 jekyll-theme-chirpy에서 다운받은 코드를 clone한 폴더에 압축해제한 후, push했을 때Actions에서 빌드하는 도중에 계속 오류가 발생하였다.  .travis.yml, _posts 삭제          현재 버전에서 Gemfile.lock은 존재X (.gitignore에 해당 파일명이 추가되어 있음)        .github/workflows/pages-deploy.yml.hook 파일의 .hook을 지우고, 해당 폴더의 나머지 파일 삭제  Settings &gt; Pages에서 Source와 Branch를 변경  _config.yml에서 url 등을 변경  .github/workflows/pages-deploy.yml 파일에서 버전을 수정위의 방법을 시도해보았으나 오류는 해결되지 않았다.인터넷에서 검색해본 방법들로는 각자 환경에 차이가 있는 것 같아jekyll-theme-chirpy/_posts/20xx-xx-xx-getting-started.md 파일을 참조하여 해결하였다.준비여러 테마들 중 chirpy 테마를 선택,PC에 Git이 설치되어 있고 깃허브를 사용중인 상태로 가정  Ruby, RubyGem, Jekyll, Bundler 설치          https://rubyinstaller.org/downloads/ 에서 윈도우용 Ruby Installer 다운로드 (https://jekyllrb.com/docs/installation/ 참고)      Installer 실행 후 next를 눌러 Ruby 설치를 완료하고 ruby -v 명령어로 설치 확인      사이트 생성하기  깃허브에서 jekyll-theme-chirpy를 검색 후 최신 소스를 자신의 깃허브에 Fork  fork 해온 리포지토리의 이름을 {GH_USERNAME}.github.io로 변경  리포지토리를 로컬로 clone  Ruby prompt를 관리자 권한으로 실행 후 로컬 리포지토리 경로로 이동,테마에 필요한 라이브러리 설치     cd {로컬 repo 폴더 경로} gem install jekyll bundler   bundle install          초기화 (bash tools/init.sh 명령어는 윈도우 환경에서 사용 불가 → 수동으로 진행)          .github/workflows/pages-deploy.yml.hook 에서 .hook확장자를 제거      .travis.tml 파일 삭제      Gemfile.lock 파일 삭제 (.gitignore에 들어있음)        _config.yml 수정          timezone      title      tagline      github username      social name, email, links      avatar        배포 전 로컬 서버에서 적용 확인          서버 실행        bundle exec jekyll serve                      localhost:4000로 접속하여 결과 화면 확인        배포     git add *   git commit -m \"커밋 메시지\"   git push        아바타, 배포 기본 설정, Actions"
  }
  
]

