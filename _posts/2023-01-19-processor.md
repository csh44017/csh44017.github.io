---
title:  "머신러닝에 사용되는 프로세서"
excerpt: "머신러닝에 사용되는 프로세서 정리"

categories:
  - ML
tags:
  - [Processor]

toc: true
toc_sticky: true

published: true

date: 2023-01-19
last_modified_at: 2023-08-20
---

## 프로세서  
### CPU(Central Processing Unit)  
**컴퓨터 시스템의 중앙 처리 장치**로 두뇌의 역할을 한다.  

다양한 환경에서 작업을 빠르게 수행하기 위해 복잡한 ALU(산술논리장치)의 구조를 가지고 있는 대신에 **하나의 명령어로 처리할 수 있는 기능이 많고 각종 제어 처리를 담당**한다.  

멀티태스킹을 위해 나눈 작업들에 우선순위를 지정하고 전환하며 가상 메모리를 관리하는 등 컴퓨터를 지휘하는 역할을 수행한다.  
컴퓨터 프로그램은 대부분 복잡한 순서를 가진 알고리즘으로 동작하기 때문에 CPU를 사용하는 것이 적절하다.  
<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/4b748661-6dba-482f-81c0-8bc1f7933058" width="300" height="120">  
</div>  

(**직렬처리에 최적화된 몇 개의 코어**로 구성)  

- 장점  
  - 다양한 프로그래밍 작업에서 사용 가능  
  - 전력 소비가 상대적으로 적음  
- 단점  
  - 병렬처리 작업이 제한적임  
<br><br>  

### GPU(Graphics Processing Unit)  
그래픽 처리 장치로 **특화된 연산을 빠른 속도로 처리**하기 위해 단순한 ALU를 여러 개 갖고 있는 구조로 되어있다.  

영상 작업은 하나의 픽셀마다 연산을 하기 때문에 처음에는 CPU에서 데이터를 보내 빠르게 그래픽 처리를 하기 위한 목적으로 만들어졌지만,  
**반복적이고 비슷한 대량의 연산을 병렬적으로 나누어 수행**하는 방법 덕분에 결과적으로 CPU 보다 훨씬 빠른 연산 속도를 보여주면서 딥러닝 모델 훈련 및 실행에 사용되기 시작해 좋은 성능을 내고 있다.  

<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/ea8b45d5-bdef-4c1f-a5f5-6a1044ef9b5e" width="500" height="200">  
</div>  

(**병렬처리용으로 설계된 수 천 개의 효율적인 코어**로 구성)  

코어 하나의 연산 능력이 높아 고가인 CPU 코어를 GPU 처럼 수천개씩 붙여 연산하는 것은 비용이나 전력, 기술적으로 비효율적이기 때문에 GPU를 사용하여 병렬 연산을 한다.  
하지만 이러한 GPU도 결국 CPU의 제어를 받으며 계산된 AI 결과도 CPU를 통해 제어한다.  

- 장점  
  - 대규모 데이터셋과 복잡한 모델을 효율적으로 처리하여 시간을 크게 단축시킬 수 있음  
- 단점  
  - 전력 소비가 큼  
<br>  

#### CPU vs GPU  
수천 개의 코어를 가지고 있어 병렬적인 작업(Paraller Task)에서 강점을 발휘하는 GPU의 사용이 무조건 CPU보다 좋은 성능을 내는 것은 아니다.  

- 작업 처리 방식  
  CPU는 4~10개 내외로 적은 수의 코어만을 가지고 있지만 **코어 자체는 GPU보다 고성능이기 때문에 순차적인 작업(Sequential Task)에서 강점**을 가지고 있다.  
  따라서 병렬도가 낮고 연산식과 데이터가 함께 바뀌는 경우에는 CPU가 더 강력한 컴퓨팅 파워를 발휘한다.  

  CPU는 연산식과 데이터가 랜덤하게 변하는 환경을 가정하여 설계했지만,  
  GPU는 제어부가 상대적으로 부실하기 때문에 이런 환경에서는 ALU가 작업을 하지 않고 노는 시간이 생긴다.  
  (예를 들어 if문을 사용하면 코드가 두 개로 갈라지는데, 이를 CPU에서 처리하지 않고 GPU에서 돌아갈 코드로 넣으면  
  나뉘어진 데이터의 양이 GPU의 가용 자원을 전부 활용할 정도가 아닐 경우, 앞쪽 코드가 다 처리된 후에 반대편 코드의 계산을 재개하기 때문에 반대편 데이터를 대기시켜놓으면서 자원을 활용하지 못해 성능이 떨어질 수 있다.)

- 데이터 통신에서의 병목  
  **CPU와 GPU 간에는 서로 PCI-E를 통해서 통신**하는데 통신 대역폭이 VGA의 로컬 메모리 대역폭보다 부족하고,  
  물리적으로 떨어져 있다보니 레이턴시가 생겨 데이터 전송에서 병목현상이 발생해 성능이 저하되는 경우가 있다.  
  - PCI-E(Peripheral Component Interconnect Express)  
    : 컴퓨터 시스템에서 하드웨어 컴포넌트 간에 데이터 통신을 할 수 있게 해주는 컴퓨터 버스 표준  

  작은 데이터를 하나하나 던져주면 **GPU의 처리속도가 빨라도 데이터를 보내고 받는 시간에서 많이 잡아먹기 때문에 성능이 나오지 않는다.**  
  (데이터셋이 작은 경우에는 오히려 CPU만으로 연산하는 것이 GPU를 사용했을 때 보다 빠르거나 별 차이가 없을 때가 있었다.)  
  <div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/ee832210-7482-4aa2-a49b-5c4922de4d9b" width="300" height="300">  
  </div>  

  - 일반적인 CPU 프로그래밍  
    1. 데이터를 가져옴  
    2. 로직에 넣음  
    3. 결과를 사용  
  <br>  

  - GPU 연산 프로그래밍  
    1. 데이터를 가져옴  
    2. GPU에 전송할 데이터를 준비  
    3. GPU로 데이터 전송  
    4. 결과를 기다림  
    5. GPU에서 결과 데이터를 수신  
    6. 수신한 데이터에서 사용할 결과를 추출  
  <br>  

  이러한 과정 때문에 <span style="color: red;">CPU 입장에서는 한번 데이터를 주고 받는데 상당한 시간이 소요</span>되고 이를 개선하기 위해 한번에 데이터를 묶어서 보내는 '배치 학습 방법'이 나온 것 같다.  
<br>  

#### (참고) GPU 연산을 위한 요구사항  
- 프로그램 가능한 셰이더  
  그래픽 카드가 기본 지원하지 않는 셰이더를 그릴 수 있어 렌즈 효과, 변위 매핑, 필드 깊이 등의 추가적인 표현이 가능해지고 이를 이용하여 연산  
- 데이터 자료형 추가  
  일반 그래픽 응용처럼 모든 계산이 행렬식으로 처리되지는 않기 때문에 필요  
- 소프트웨어 적으로 변환시키는 라이브러리  
  CUDA, OpenCL, 등  
<br><br>  

### MPU(Micro Processor Unit)  
연산만을 목적으로 만들어진 CPU역할을 하는 장치로 ALU와 연산 입력 값을 처리하기 위한 시프트 레지스터로 이루어져 있다.  
(RAM, ROM, I/O 등의 장치를 추가해주어야 작동 가능)  

특정 딥러닝 작업에 특화된 하드웨어 가속기로 사용  
- 장점  
  - 딥러닝 작업을 최적화하기 위해 설계되어 빠른 성능을 제공  
  - GPU보다 낮은 전력을 소비  
- 단점  
  - 딥러닝 이외의 다른 종류 작업에는 제한적  
  - 성능 최적화 지원이 특정 딥러닝 프레임워크에 한정  
<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/e6c070c7-bc6c-47be-b012-8510159d95d4" width="100" height="100">  
</div>  
<br>  

#### MCU(Micro Controller Unit)  
마이크로프로세서(초소형 연산 처리 장치)와 입출력 모듈을 하나의 칩으로 만든 장치  
연산뿐만 아니라 주변의 장치를 제어한다.  

(CPU 코어, 메모리, 프로그램 가능한 입출력으로 구성되어 있어 정해진 기능을 수행하도록 프로그래밍하고 메모리에 써넣음)  

<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/d8d8483f-4053-4c41-ba20-b6f47335b1c0" width="150" height="150">  
</div>  
<br><br>  

### TPU(Tensor Processing Unit)  
구글에서 머신러닝 워크로드를 빠르게 처리하기 위해 설계한 ASIC(Application Specific Integrated Circuit)  
Tensorflow나 TFLite를 프레임워크로 사용할 때만 쓸 수 있다.  
<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/38e86c64-2e99-4e1e-a36f-4c748a61ec16" width="250" height="200">  
</div>  

- Edge TPU  
  저전력으로 최적화하여 Edge용으로 공개한 Edge TPU도 존재하며, 스마트폰 같은 소형 기기에서 볼 수 있다.  
  [Edge TPU 성능 비교](https://coral.ai/docs/edgetpu/benchmarks/){:target="_blank"}  
<br><br>  

### DPU(Data Processing Unit)  
데이터센터에서 주로 네트워크, 보안, 저장소, 가상화 및 기타 데이터 중심 작업을 수행하는 데 사용되는 데이터 중심 가속 컴퓨팅을 위한 장치이다.  
고성능 네트워크 인터페이스로 데이터를 파싱(parsing) 및 처리하고, 데이터를 GPU 및 CPU로 효율적으로 전송한다.  
<div align="center">  
  <img src="https://github.com/csh44017/csh44017.github.io/assets/77605589/7d1d7536-e713-4329-a3c4-3d79c3382969" width="200" height="200">  
</div>  
