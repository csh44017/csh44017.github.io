---
title:  "머신러닝을 위한 GPU"
excerpt: "머신러닝에 사용할 GPU의 배경지식 정리"

categories:
  - ML
tags:
  - [Processor]

toc: true
toc_sticky: true

published: true

date: 2023-01-24
last_modified_at: 2023-08-20
---

## GTX vs RTX  
NVIDIA 그래픽카드  

- GTX 시리즈는 3D 오브젝트를 2D 픽셀화하여 처리하는 방식인 래스터화(Rasterization) 기술을 사용  
- RTX 시리즈는 전통적인 **래스터화** 기술에 빛의 경로를 실시간으로 시뮬레이션하는 **레이트레이싱(Ray Tracing)** 기술을 추가로 지원하여 빛과 그림자 등의 디테일한 효과를 구현하며 더 높은 그래픽 성능을 제공  
- 딥러닝 알고리즘을 가속화하기 위한 텐서 코어를 포함하여 아키텍처에 차이가 있음  
- 일반적으로 RTX 시리즈가 더 좋은 성능을 가지며 그와 함께 전력 소비도 높다.  
- 가격이 비쌈  


### 딥러닝에서의 병렬 연산  
모델 훈련을 위해 주 메모리(RAM)에 담겨서 CPU에서 연산할 데이터셋의 일부 또는 전체(배치 단위)를 병렬 연산으로 빠르게 처리하기 위해 GPU의 전용 메모리(VRAM)로 이동시켜서 계산을 수행한다.  
RAM에서 VRAM으로 데이터 이동은 CPU에서 관리하여 DMA를 통해 효율적으로 전송된다.  
(모델과 가중치도 데이터셋과 같이 이동하여 모델의 가중치를 업데이트하고 이 가중치를 다시 RAM으로 전송)  

1. 딥러닝 모델의 아키텍처와 초기 가중치를 CPU와 연결된 주 메모리(RAM)에 로드  
2. 모델 훈련을 시작 전에 GPU의 VRAM으로 모델 아키텍처와 가중치를 전송  
3. 디스크에 저장된 전체 데이터셋에서 배치 단위로 데이터를 분할하여 RAM으로 로드  
(전체 데이터셋은 너무 크므로 배치 단위로 수행)  
4. GPU에서 해당 배치에 액세스할 수 있도록 VRAM으로 전송  
5. 순전파와 역전파를 수행하여 VRAM에 머무르고 있는 현재 가중치를 업데이트  
(모든 배치에 대해 계산이 끝날 때까지 업데이트된 가중치가 다시 RAM으로 이동하지 않고 다음 배치 데이터 처리에 사용됨)  
6. 모든 배치에 대해 훈련을 마치고 최종적으로 업데이트된 가중치를 VRAM에서 다시 RAM으로 전송  
7. 결과를 디스크에 저장  
<br>  

- 멀티 GPU를 사용하여 병렬 처리를 하는 경우  
  1. 각 GPU에 동일한 모델의 복사본을 로드  
  2. 각 GPU에 배치 단위로 나눈 데이터셋(미니 배치)을 균등하게 분배  
  3. 각 GPU가 할당된 데이터를 독립적으로 순전파와 역전파를 수행하여 그래디언트를 계산  
  4. 모든 GPU에서 계산된 그래디언트를 CPU나 주 GPU에서 집계하여 평균 그래디언트를 계산  
  5. 평균 그래디언트를 사용하여 가중치를 업데이트하고 모든 GPU에 다시 복사하여 동기화  
